<!DOCTYPE html>
<!-- saved from url=(0043)http://localhost:3000/#open-source-workflow -->
<html lang="en" class="dark" style="scroll-padding:0"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Performing Object Detection on Drone Orthomosaics with Meta's Segment Anything Model (SAM)</title><meta property="og:title" content="Performing Object Detection on Drone Orthomosaics with Meta&#39;s Segment Anything Model (SAM)"><meta name="generator" content="mystmd"><meta name="description" content="This article presents a workflow that utilizes SAM&#39;s automatic mask generation skill to effectively perform the task of object detection zero-shot on a high-resolution drone orthomosaic. The generated output is 20% more spatially accurate than that produced using proprietary software, with 400% greater IoU."><meta property="og:description" content="This article presents a workflow that utilizes SAM&#39;s automatic mask generation skill to effectively perform the task of object detection zero-shot on a high-resolution drone orthomosaic. The generated output is 20% more spatially accurate than that produced using proprietary software, with 400% greater IoU."><meta name="keywords" content="object detection, spatial localization, drone orthomosaic"><meta name="image" content="http://localhost:3100/trimmer-cc850f3b5f2eb92884f6511d6db638c6.jpg"><meta property="og:image" content="http://localhost:3100/trimmer-cc850f3b5f2eb92884f6511d6db638c6.jpg"><link rel="stylesheet" href="./index_files/app-QQ3IDNE5.css"><link rel="stylesheet" href="./index_files/thebe-core-VKVHG5VY.css"><link rel="stylesheet" href="./index_files/mpl_widget.css"><link rel="stylesheet" href="./index_files/font-awesome.css"><link rel="stylesheet" href="./index_files/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"><link rel="icon" href="http://localhost:3000/favicon.ico"><link rel="stylesheet" href="./index_files/myst-theme.css"><script src="./index_files/thebe-core.min.js.download" async="true" type="text/javascript"></script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="http://localhost:3000/#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="fixed top-4 right-4 z-50"><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode." aria-label="Toggle theme between light and dark mode."><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button></div><article class="article content article-left-grid subgrid-gap"><div class="hidden"></div><header class="relative col-screen"><div class="absolute article-left-grid subgrid-gap col-screen bg-no-repeat bg-cover bg-top w-full h-full -z-10 pointer-events-none" style="background-image:url(http://localhost:3100/banner-a36fcce9f637cecc37099063b2c3a3ae.png)"></div><div class="w-full relative col-screen article article-left-grid subgrid-gap my-[2rem] pb-[1rem] md:my-[4rem]"><div class="col-page-right shadow-2xl bg-white/80 dark:bg-black/80 backdrop-blur"><div class="flex w-full align-middle py-2 mb-[1rem] text-sm px-4 w-full bg-white/80 dark:bg-black/80 col-page-right"><div class="flex-none pr-2 smallcaps">Research Article</div><div class="flex-none mr-2 hidden pl-2 border-l md:block"><a href="https://proceedings.scipy.org/" class="font-semibold no-underline smallcaps" title="Python in Science Conference">Python in Science Conference</a></div><div class="flex-grow"></div><div class="hidden sm:block"><a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer" class="opacity-50 hover:opacity-100 text-inherit hover:text-inherit" aria-label="Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mx-1"><title>Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg></a><a href="https://en.wikipedia.org/wiki/Open_access" target="_blank" rel="noopener noreferrer" title="Open Access" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="mr-1 inline-block opacity-60 hover:opacity-100 hover:text-[#E18435]"><path d="M17.1 12.6h-2V7.5c0-1.7-1.4-3.1-3-3.1-.8 0-1.6.3-2.2.9-.6.5-.9 1.3-.9 2.2v.7H7v-.7c0-1.4.5-2.7 1.5-3.7s2.2-1.5 3.6-1.5 2.6.5 3.6 1.5 1.5 2.3 1.5 3.7v5.1z"></path><path d="M12 21.8c-.8 0-1.6-.2-2.3-.5-.7-.3-1.4-.8-1.9-1.3-.6-.6-1-1.2-1.3-2-.3-.8-.5-1.6-.5-2.4s.2-1.6.5-2.4c.3-.7.7-1.4 1.3-2s1.2-1 1.9-1.3c.7-.3 1.5-.5 2.3-.5.8 0 1.6.2 2.3.5.7.3 1.4.8 1.9 1.3.6.6 1 1.2 1.3 2 .3.8.5 1.6.5 2.4s-.2 1.6-.5 2.4c-.3.7-.7 1.4-1.3 2-.6.6-1.2 1-1.9 1.3-.7.3-1.5.5-2.3.5zm0-10.3c-2.2 0-4 1.8-4 4.1s1.8 4.1 4 4.1 4-1.8 4-4.1-1.8-4.1-4-4.1z"></path><circle cx="12" cy="15.6" r="1.7"></circle></svg></a></div></div><div class="flex flex-col mb-10 md:flex-row"><div id="skip-to-frontmatter" aria-label="article frontmatter" class="flex-grow pt-6 px-6 col-body"><h1 class="mb-0">Performing Object Detection on Drone Orthomosaics with Meta's Segment Anything Model (SAM)</h1><div><span class="font-semibold text-sm inline-block"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R1oqf8p:" data-state="closed">Nicholas McCarty</button><a class="ml-1" href="mailto:nick@upskilled.consulting" title="Nicholas McCarty &lt;nick@upskilled.consulting&gt;" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1rem" height="1rem" class="inline-block text-gray-400 hover:text-blue-400 -translate-y-[0.1em]"><path d="M21.8 18c0 1.1-.9 2-1.9 2H4.2c-1.1 0-1.9-.9-1.9-2V9.9c0-.5.3-.7.8-.4l7.8 4.7c.7.4 1.7.4 2.4 0L21 9.5c.4-.2.8-.1.8.4V18z"></path><path d="M21.8 6c0-1.1-.9-2-1.9-2H4.2c-1.1 0-2 .9-2 2v.4c0 .5.3 1.1.8 1.3l8.5 5.1c.2.1.7.1.9 0l8.6-5c.4-.3.8-.9.8-1.3-.1-.1-.1-.5 0-.5z"></path></svg></a><a class="ml-1" href="https://orcid.org/0009-0001-3727-9178" target="_blank" rel="noopener noreferrer" title="ORCID (Open Researcher and Contributor ID)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1rem" height="1rem" class="inline-block text-gray-400 hover:text-[#A9C751] -translate-y-[0.1em]"><path d="M21.8 12c0 5.4-4.4 9.8-9.8 9.8S2.2 17.4 2.2 12 6.6 2.2 12 2.2s9.8 4.4 9.8 9.8zM8.2 5.8c-.4 0-.8.3-.8.8s.3.8.8.8.8-.4.8-.8-.3-.8-.8-.8zm2.3 9.6h1.2v-6h1.8c2.3 0 3.3 1.4 3.3 3s-1.5 3-3.3 3h-3v1.1H9V8.3H7.7v8.2h5.9c3.3 0 4.5-2.2 4.5-4.1s-1.2-4.1-4.3-4.1h-3.2l-.1 7.1z"></path></svg></a></span></div><div class="flex mt-2 text-sm font-light"><time datetime="2025-07-10" class="">July 10, 2025</time></div></div><div class="pt-5 md:self-center h-fit lg:pt-0 col-body lg:col-margin-right-inset"></div></div></div></div></header><main id="main" class="article-left-grid subgrid-gap col-screen"><div class="hidden"></div><div class="block my-10 lg:sticky lg:top-0 lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:24px"><div data-state="open"><nav aria-label="Document Outline" class="not-prose overflow-y-auto transition-opacity duration-700 relative pt-[2px]" style="top: 0px; max-height: calc(-20px + 100vh);"><div class="flex flex-row gap-2 mb-4 text-sm leading-6 uppercase rounded-lg text-slate-900 dark:text-slate-100">In this article<button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" type="button" aria-controls="radix-:r0:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:r0:" class="CollapsibleContent" style="transition-duration: 0s; animation-name: none; --radix-collapsible-content-height: 632px; --radix-collapsible-content-width: 403.9312438964844px;"><ul class="text-sm leading-6 text-slate-400"><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-900 dark:text-slate-50 pr-2 pl-2" href="http://localhost:3000/#introduction">Introduction</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-900 dark:text-slate-50 pr-2 pl-2" href="http://localhost:3000/#motivation">Motivation</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-900 dark:text-slate-50 pr-2 pl-2" href="http://localhost:3000/#approach">Approach</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-900 dark:text-slate-50 pr-2 pl-2" href="http://localhost:3000/#methodology">Methodology</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-500 dark:text-slate-300 pr-2 pl-4" href="http://localhost:3000/#data-and-environment">Data and Environment</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-500 dark:text-slate-300 pr-2 pl-4" href="http://localhost:3000/#workflow">Workflow</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-500 dark:text-slate-300 pr-2 pl-8 text-xs" href="http://localhost:3000/#data-ingestion-and-preprocessing">Data Ingestion and Preprocessing</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-500 dark:text-slate-300 pr-2 pl-8 text-xs" href="http://localhost:3000/#mask-generation">Mask Generation</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-500 dark:text-slate-300 pr-2 pl-8 text-xs" href="http://localhost:3000/#post-processing">Post-Processing</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-500 dark:text-slate-300 pr-2 pl-8 text-xs" href="http://localhost:3000/#accuracy-evaluation">Accuracy Evaluation</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-500 dark:text-slate-300 pr-2 pl-8 text-xs" href="http://localhost:3000/#benchmarking">Benchmarking</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-900 dark:text-slate-50 pr-2 pl-2" href="http://localhost:3000/#results">Results</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-500 dark:text-slate-300 pr-2 pl-4" href="http://localhost:3000/#proprietary-workflow">Proprietary Workflow</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-500 dark:text-slate-300 pr-2 pl-4" href="http://localhost:3000/#open-source-workflow">Open Source Workflow</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-900 dark:text-slate-50 pr-2 pl-2" href="http://localhost:3000/#discussion">Discussion</a></li><li class="border-l-2 hover:border-l-blue-500 text-blue-600 border-l-blue-500 bg-blue-50 dark:bg-slate-800"><a class="block p-1 text-blue-600 dark:text-white font-bold pl-2" href="http://localhost:3000/#conclusion">Conclusion</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-900 dark:text-slate-50 pr-2 pl-2" href="http://localhost:3000/#conflicts-of-interest">Conflicts of Interest</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-900 dark:text-slate-50 pr-2 pl-2" href="http://localhost:3000/#ai-usage-disclosure">AI Usage Disclosure</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-900 dark:text-slate-50 pr-2 pl-2" href="http://localhost:3000/#code">Code</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-900 dark:text-slate-50 pr-2 pl-2" href="http://localhost:3000/#appendix-a">Appendix A</a></li><li class="border-l-2 hover:border-l-blue-500 border-l-gray-300 dark:border-l-gray-50"><a class="block p-1 text-slate-500 dark:text-slate-300 pr-2 pl-4" href="http://localhost:3000/#accuracy-evaluation-methodology">Accuracy Evaluation Methodology</a></li></ul></div></nav></div></div><div id="skip-to-article"></div><div><div><h2 id="abstract" class="mb-3 text-base font-semibold group">Abstract<a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#abstract" title="Link to Abstract" aria-label="Link to Abstract">¶</a></h2><div class="px-6 py-1 mb-3 rounded-sm bg-slate-50 dark:bg-slate-800"><div class="col-body"><p>Accurate and efficient object detection and spatial localization in remote sensing imagery is a persistent challenge. In the context of precision agriculture, the extensive data annotation required by conventional deep learning models poses additional challenges. This paper presents a fully open source workflow leveraging Meta AI’s Segment Anything Model (SAM) for zero-shot segmentation, enabling scalable object detection and spatial localization in high-resolution drone orthomosaics without the need for annotated image datasets. Model training and/or fine-tuning is rendered unnecessary in our precision agriculture-focused use case. The presented end-to-end workflow takes high-resolution images and quality control (QC) check points as inputs, automatically generates masks corresponding to the objects of interest (empty plant pots, in our given context), and outputs their spatial locations in real-world coordinates. Detection accuracy (required in the given context to be within 3 cm) is then quantitatively evaluated using the ground truth QC check points and benchmarked against object detection output generated using commercially available software. Results demonstrate that the open source workflow achieves superior spatial accuracy — producing output <code>20% more spatially accurate</code>, with <code>400% greater IoU</code> — while providing a scalable way to perform spatial localization on high-resolution aerial imagery (with ground sampling distance, or GSD, &lt; 30 cm).</p></div></div></div><div class="mb-10 group"><span class="mr-2 font-semibold">Keywords:</span><span class="after:content-[&#39;,&#39;] after:mr-1">object detection</span><span class="after:content-[&#39;,&#39;] after:mr-1">spatial localization</span><span class="">drone orthomosaic</span><a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#keywords" title="Link to Keywords" aria-label="Link to Keywords">¶</a></div></div><h2 id="introduction" class="relative group"><span class="mr-3 select-none">1</span><span class="heading-text">Introduction</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#introduction" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Image segmentation is a critical task in geospatial analysis, enabling the identification and extraction of relevant features from high resolution remote sensing imagery <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.21105/joss.05663" target="_blank" rel="noreferrer" class="hover-link">Wu &amp; Osco, 2023</a></cite></span>. However, extracting actionable information (i.e., object detection and spatial localization) can be constrained by the need for large, labeled datasets to train deep learning models in order to then perform inference and (hopefully) produce the desired output. This bottleneck is particularly acute in agricultural domains, where variability in conditions and object types complicates manual annotation <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://arxiv.org/abs/2306.16623" target="_blank" rel="noreferrer" class="hover-link">Osco <em>et al.</em>, 2023</a></cite></span>.</p><p>Recent advances in foundation models, such as Meta AI’s Segment Anything Model (SAM), offer a promising path forward. SAM is designed for promptable “zero-shot” segmentation. “Prompt engineering”, in this context, involves using points and bounding boxes to focus the model’s efforts on more efficiently generating masks corresponding to objects of interest <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://arxiv.org/abs/2310.01845" target="_blank" rel="noreferrer" class="hover-link">Mayladan <em>et al.</em>, 2024</a></cite></span>. Providing these prompts allows accurate masks to be generated for novel objects (ones not included in SAM’s training corpus), without domain-specific training. Masks can also be generated automatically with no such prompting. SAM’s automatic mask generator will effectively “detect” everything using open source model checkpoints and generate masks for each object in a provided image <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://arxiv.org/abs/2304.02643" target="_blank" rel="noreferrer" class="hover-link">Kirillov <em>et al.</em>, 2023</a></cite></span>.</p><p>While SAM’s ability to generalize is impressive <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://arxiv.org/abs/2304.02643" target="_blank" rel="noreferrer" class="hover-link">Kirillov <em>et al.</em>, 2023</a></cite><cite class="" data-state="closed"><a href="https://arxiv.org/abs/2306.16623" target="_blank" rel="noreferrer" class="hover-link">Osco <em>et al.</em>, 2023</a></cite></span>, its performance on remote sensing imagery and fine-grained features requires careful workflow integration and evaluation <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.21105/joss.05663" target="_blank" rel="noreferrer" class="hover-link">Wu &amp; Osco, 2023</a></cite></span>. This paper describes a comprehensive, open source workflow for object detection and spatial localization in high-resolution remote sensing imagery, built around SAM and widely used geospatial Python libraries <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.5281/zenodo.5884351" target="_blank" rel="noreferrer" class="hover-link">GDAL/OGR contributors, 2025</a></cite><cite class="" data-state="closed"><a href="https://doi.org/10.5281/zenodo.5597138" target="_blank" rel="noreferrer" class="hover-link">Gillies <em>et al.</em>, 2025</a></cite><cite class="" data-state="closed"><a href="https://doi.org/10.5281/zenodo.3946761" target="_blank" rel="noreferrer" class="hover-link">Jordahl <em>et al.</em>, 2020</a></cite><cite class="" data-state="closed"><a href="https://github.com/rasterio/rasterio" target="_blank" rel="noreferrer" class="hover-link">Gillies &amp; others, 2013</a></cite></span>. The complete process is delineated, from data loading and preprocessing to mask generation, post-processing, and quantitative accuracy assessment, culminating in a robust comparison with the results produced using the proprietary software (see <span data-state="closed"><a href="http://localhost:3000/#code" class="hover-link">code</a></span>). Precision, accuracy, F1 score, mean deviation (in cm), and Intersection-over-Union (IoU) are calculated in order to quantify the relative quality of the output produced using each workflow<span id="fnref-LdJ8yuaTrF" class="" data-state="closed"><sup class="hover-link"><a class="no-underline text-inherit hover:text-inherit font-normal hover:underline" href="http://localhost:3000/#fn-footnote-1" title="Link to Footnote" aria-label="Link to Footnote">[<!-- -->1<!-- -->]</a></sup></span>.</p><h2 id="motivation" class="relative group"><span class="mr-3 select-none">2</span><span class="heading-text">Motivation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#motivation" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Precision agriculture relies on accurate object detection for tasks such as plant counting, health monitoring, and targeted resource distribution. Traditional deep learning approaches can become hindered by the cost and effort of generating carefully annotated data, limiting scalability and accessibility. Proprietary solutions, while effective, can be expensive and opaque, impeding reproducibility and customization.</p><figure id="fig-trimmer" class="fig-figure"><img id="xMBO3qtJqg" style="margin:0 auto" src="./index_files/trimmer-cc850f3b5f2eb92884f6511d6db638c6.jpg" alt="The derived centroids of the objects detected in the drone orthomosaic are used to automate this nursery trimmer." data-canonical-url="trimmer.jpg"><figcaption class="group"><p><a class="no-underline text-inherit hover:text-inherit mr-1 font-semibold text-inherit hover:text-inherit hover:font-semibold select-none hover:underline" href="http://localhost:3000/#fig-trimmer" title="Link to this figure" aria-label="Link to this figure">Figure&nbsp;<!-- -->1<!-- -->:</a>The derived centroids of the objects detected in the drone orthomosaic are used to automate this nursery trimmer.</p></figcaption></figure><p>SAM’s zero-shot segmentation capability directly addresses the data annotation bottleneck, enabling rapid deployment in novel contexts. By developing an open source workflow around SAM, an end-to-end pipeline is created which allows for the quantitative evaluation of spatial accuracy with respect to objects detected in high-resolution aerial imagery. This modular workflow can also be repurposed as an automated data annotation pipeline for downstream model training/fine-tuning, if required.</p><h2 id="approach" class="relative group"><span class="mr-3 select-none">3</span><span class="heading-text">Approach</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#approach" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Our approach integrates SAM’s segmentation strengths with traditional geospatial data processing techniques, which lends itself to our precision agriculture use case. The workflow, like any other, can be thought of as a sequence of steps (visualized above and described below), each with their own sets of substeps:</p><ul><li><strong>Data Ingestion</strong>: Loading GeoTIFF orthomosaics and QC point CSVs, extracting spatial bounds and coordinate reference systems (CRS) using Rasterio or GDAL.</li><li><strong>Preprocessing</strong>: Filtering QC points to those within image bounds, standardizing coordinate columns, and saving filtered data for downstream analysis.</li><li><strong>Mask Generation</strong>: Tiling large images for efficient processing, running SAM’s automatic mask generator (<strong><em>ViT-H</em></strong> variant) on each tile, and filtering masks by confidence.</li><li><strong>Post-Processing</strong>: Converting masks to polygons, filtering by area and compactness, merging overlapping geometry, and extracting centroids.</li><li><strong>Accuracy Evaluation</strong>: Calculating point-to-centroid deviations (in centimeters) between detected objects and QC points, compiling results, and generating visual and tabular reports.</li><li><strong>Benchmarking</strong>: Quantitatively comparing SAM-based results against the evaluated output using identical evaluation metrics (precision, recall, IoU, etc.; see <span data-state="closed"><a href="http://localhost:3000/#accuracy-evaluation-methodology" class="hover-link">Appendix A</a></span> for details).</li></ul><p>It should be noted that there are no model training or fine-tuning steps included in our workflow, as we are using a foundation model to generate masks. This is analogous to using ChatGPT to generate text, which does not require users to train or fine-tune the underlying foundation model in order to do so.</p><p>This approach is carried out entirely using open source Python libraries, ensuring transparency and extensibility.</p><h2 id="methodology" class="relative group"><span class="mr-3 select-none">4</span><span class="heading-text">Methodology</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#methodology" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h3 id="data-and-environment" class="relative group"><span class="mr-3 select-none">4.1</span><span class="heading-text">Data and Environment</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#data-and-environment" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><ul><li><strong>Imagery</strong>: High-resolution GeoTIFF orthomosaic.<ul><li><strong>Image size</strong>: 18,200 x 55,708; 1,013,885,600 pixels</li><li><strong>Total area</strong>: 545,243 sq ft; 12.5 acres</li><li><strong>GSD</strong>: 0.71 cm</li></ul></li><li><strong>Ground Truth</strong>: QC points in CSV format, containing spatial coordinates and unique identifiers.</li><li><strong>Coordinate Reference System (CRS) Transformations</strong>: All spatial operations are performed using the NAD83 CRS (EPSG:6859), with reprojection to the WGS84 CRS (EPSG:4326) for downstream reporting and nursery trimmer automation.</li><li><strong>Dependencies</strong><span id="fnref-eCEzLspsjq" class="" data-state="closed"><sup class="hover-link"><a class="no-underline text-inherit hover:text-inherit font-normal hover:underline" href="http://localhost:3000/#fn-footnote-2" title="Link to Footnote" aria-label="Link to Footnote">[<!-- -->2<!-- -->]</a></sup></span>:<ul><li>GDAL <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.5281/zenodo.5884351" target="_blank" rel="noreferrer" class="hover-link">GDAL/OGR contributors, 2025</a></cite></span></li><li>GeoPandas <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.5281/zenodo.3946761" target="_blank" rel="noreferrer" class="hover-link">Jordahl <em>et al.</em>, 2020</a></cite></span></li><li>Matplotlib <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.1109/MCSE.2007.55" target="_blank" rel="noreferrer" class="hover-link">Hunter, 2007</a></cite></span></li><li>NumPy <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.1038/s41586-020-2649-2" target="_blank" rel="noreferrer" class="hover-link">Harris <em>et al.</em>, 2020</a></cite></span></li><li>OpenCV <span class="cite-group parenthetical"><cite class="" data-state="closed"><span class="hover-link">Bradski, 2000</span></cite></span></li><li>OpenPyXL <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://openpyxl.readthedocs.io/" target="_blank" rel="noreferrer" class="hover-link">Gazoni &amp; Clark, 2024</a></cite></span></li><li>Pandas <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.5281/zenodo.3509134" target="_blank" rel="noreferrer" class="hover-link">The Pandas Development Team, 2020</a></cite><cite class="" data-state="closed"><a href="https://doi.org/10.25080/Majora-92bf1922-00a" target="_blank" rel="noreferrer" class="hover-link">McKinney, 2010</a></cite></span></li><li>Pillow <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://buildmedia.readthedocs.org/media/pdf/pillow/latest/pillow.pdf" target="_blank" rel="noreferrer" class="hover-link">Clark, 2015</a></cite></span></li><li>Rasterio <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://github.com/rasterio/rasterio" target="_blank" rel="noreferrer" class="hover-link">Gillies &amp; others, 2013</a></cite></span></li><li>Segment Anything<span id="fnref-r9Q5ldsRpN" class="" data-state="closed"><sup class="hover-link"><a class="no-underline text-inherit hover:text-inherit font-normal hover:underline" href="http://localhost:3000/#fn-footnote-3" title="Link to Footnote" aria-label="Link to Footnote">[<!-- -->3<!-- -->]</a></sup></span> <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://arxiv.org/abs/2304.02643" target="_blank" rel="noreferrer" class="hover-link">Kirillov <em>et al.</em>, 2023</a></cite></span></li><li>Shapely <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.5281/zenodo.5597138" target="_blank" rel="noreferrer" class="hover-link">Gillies <em>et al.</em>, 2025</a></cite></span></li><li>Torch <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://arxiv.org/abs/1912.01703" target="_blank" rel="noreferrer" class="hover-link">Paszke <em>et al.</em>, 2019</a></cite></span></li></ul></li></ul><h3 id="workflow" class="relative group"><span class="mr-3 select-none">4.2</span><span class="heading-text">Workflow</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#workflow" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><figure id="fig-workflow" class="fig-figure"><img id="rdq0CEZ0zC" style="margin:0 auto" src="./index_files/workflow-af7b467f0709fce0583142963a37004f.png" alt="The high-level workflow steps." data-canonical-url="workflow.png"><figcaption class="group"><p><a class="no-underline text-inherit hover:text-inherit mr-1 font-semibold text-inherit hover:text-inherit hover:font-semibold select-none hover:underline" href="http://localhost:3000/#fig-workflow" title="Link to this figure" aria-label="Link to this figure">Figure&nbsp;<!-- -->2<!-- -->:</a>The high-level workflow steps.</p></figcaption></figure><h4 id="data-ingestion-and-preprocessing" class="relative group"><span class="mr-3 select-none">4.2.1</span><span class="heading-text">Data Ingestion and Preprocessing</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#data-ingestion-and-preprocessing" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><figure id="fig-ingestion-and-preprocessing" class="fig-figure"><img id="dDCnwkInZw" style="margin:0 auto" src="./index_files/ingestion-and-prepro-5dd37aadcfd09656ee0ff07de3b097af.png" alt="Data ingestion and preprocessing workflow substeps." data-canonical-url="ingestion-and-preprocessing.png"><figcaption class="group"><p><a class="no-underline text-inherit hover:text-inherit mr-1 font-semibold text-inherit hover:text-inherit hover:font-semibold select-none hover:underline" href="http://localhost:3000/#fig-ingestion-and-preprocessing" title="Link to this figure" aria-label="Link to this figure">Figure&nbsp;<!-- -->3<!-- -->:</a>Data ingestion and preprocessing workflow substeps.</p></figcaption></figure><h4 id="mask-generation" class="relative group"><span class="mr-3 select-none">4.2.2</span><span class="heading-text">Mask Generation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#mask-generation" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><figure id="fig-mask-generation" class="fig-figure"><img id="sO3rBzaKNu" style="margin:0 auto" src="./index_files/mask-generation-6063d070d6220423919c6d106fec241c.png" alt="Mask generation workflow substeps." data-canonical-url="mask-generation.png"><figcaption class="group"><p><a class="no-underline text-inherit hover:text-inherit mr-1 font-semibold text-inherit hover:text-inherit hover:font-semibold select-none hover:underline" href="http://localhost:3000/#fig-mask-generation" title="Link to this figure" aria-label="Link to this figure">Figure&nbsp;<!-- -->4<!-- -->:</a>Mask generation workflow substeps.</p></figcaption></figure><h4 id="post-processing" class="relative group"><span class="mr-3 select-none">4.2.3</span><span class="heading-text">Post-Processing</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#post-processing" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><figure id="fig-post-processing" class="fig-figure"><img id="wTlXyJhnTG" style="margin:0 auto" src="./index_files/post-processing-64beff64c6b64b117d7e944816b3c683.png" alt="Data post-processing workflow substeps." data-canonical-url="post-processing.png"><figcaption class="group"><p><a class="no-underline text-inherit hover:text-inherit mr-1 font-semibold text-inherit hover:text-inherit hover:font-semibold select-none hover:underline" href="http://localhost:3000/#fig-post-processing" title="Link to this figure" aria-label="Link to this figure">Figure&nbsp;<!-- -->5<!-- -->:</a>Data post-processing workflow substeps.</p></figcaption></figure><h4 id="accuracy-evaluation" class="relative group"><span class="mr-3 select-none">4.2.4</span><span class="heading-text">Accuracy Evaluation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#accuracy-evaluation" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><figure id="fig-accuracy-evaluation" class="fig-figure"><img id="tXPWTR0G70" style="margin:0 auto" src="./index_files/accuracy-evaluation-fa62865b14e4cead4d16dc102803fc49.png" alt="Data post-processing workflow substeps; see Appendix A for methodology details." data-canonical-url="accuracy-evaluation.png"><figcaption class="group"><p><a class="no-underline text-inherit hover:text-inherit mr-1 font-semibold text-inherit hover:text-inherit hover:font-semibold select-none hover:underline" href="http://localhost:3000/#fig-accuracy-evaluation" title="Link to this figure" aria-label="Link to this figure">Figure&nbsp;<!-- -->6<!-- -->:</a>Data post-processing workflow substeps; see <span data-state="closed"><a href="http://localhost:3000/#accuracy-evaluation-methodology" class="hover-link">Appendix A</a></span> for methodology details.</p></figcaption></figure><h4 id="benchmarking" class="relative group"><span class="mr-3 select-none">4.2.5</span><span class="heading-text">Benchmarking</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#benchmarking" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><figure id="fig-benchmarking" class="fig-figure"><img id="V3FuSPqbJK" style="margin:0 auto" src="./index_files/benchmarking-77f425bca54c3b7d70477a20d4a051ba.png" alt="Benchmarking workflow substeps; see code for methodology details." data-canonical-url="benchmarking.png"><figcaption class="group"><p><a class="no-underline text-inherit hover:text-inherit mr-1 font-semibold text-inherit hover:text-inherit hover:font-semibold select-none hover:underline" href="http://localhost:3000/#fig-benchmarking" title="Link to this figure" aria-label="Link to this figure">Figure&nbsp;<!-- -->7<!-- -->:</a>Benchmarking workflow substeps; see <span data-state="closed"><a href="http://localhost:3000/#code" class="hover-link">code</a></span> for methodology details.</p></figcaption></figure><h2 id="results" class="relative group"><span class="mr-3 select-none">5</span><span class="heading-text">Results</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#results" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h3 id="proprietary-workflow" class="relative group"><span class="mr-3 select-none">5.1</span><span class="heading-text">Proprietary Workflow</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#proprietary-workflow" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><figure id="fig-proprietary-workflow-output-evaluation" class="fig-figure"><img id="tbGNoEUJBk" style="margin:0 auto" src="./index_files/proprietary-workflow-ee60ae2669b98b1bb550af791cfc12d6.png" alt="19 false positives (FP) and hundreds of sliver polygons were observed in the output produced using the proprietary software." data-canonical-url="proprietary-workflow-output-evaluation.png"><figcaption class="group"><p><a class="no-underline text-inherit hover:text-inherit mr-1 font-semibold text-inherit hover:text-inherit hover:font-semibold select-none hover:underline" href="http://localhost:3000/#fig-proprietary-workflow-output-evaluation" title="Link to this figure" aria-label="Link to this figure">Figure&nbsp;<!-- -->8<!-- -->:</a>19 false positives (FP) and hundreds of sliver polygons were observed in the output produced using the proprietary software.</p></figcaption></figure><p>The bounding boxes that were output using this workflow (against which we are benchmarking ours) can be viewed as a layer overlain onto the GeoTIFF orthomosaic using GIS software<span id="fnref-Tfzo6FHqvW" class="" data-state="closed"><sup class="hover-link"><a class="no-underline text-inherit hover:text-inherit font-normal hover:underline" href="http://localhost:3000/#fn-footnote-4" title="Link to Footnote" aria-label="Link to Footnote">[<!-- -->4<!-- -->]</a></sup></span>. Certain inferences can be drawn from the output that we won’t go into here; what is of particular use to us is the fact that zero false negatives (FN) were observed in the output, though 19 FP were. This empirical knowledge equips us with something not usually possessed in use cases such as this: the number of true positives (TP), which allows us to leverage such metrics as precision, recall, and the harmonic mean of the two, F1 score, in order to perform a rigorous comparison (see <a target="_blank" rel="noreferrer" href="https://colab.research.google.com/drive/1pwnb14s2i7n_VAlfwhBqzDQ0cOb9oGs-?usp=sharing#sandboxMode=true&amp;scrollTo=VNWvzNKU-ePt" class="">code</a>).</p><h3 id="open-source-workflow" class="relative group"><span class="mr-3 select-none">5.2</span><span class="heading-text">Open Source Workflow</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#open-source-workflow" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><figure id="fig-open-source-workflow-output-evaluation" class="fig-figure"><img id="aLczXl8Tgs" style="margin:0 auto" src="./index_files/open-source-false-po-193be7a399470bc17c88d351fd64c91d.png" alt="18 FP were observed in the output produced using the open source workflow." data-canonical-url="open-source-false-positive-collage.png"><figcaption class="group"><p><a class="no-underline text-inherit hover:text-inherit mr-1 font-semibold text-inherit hover:text-inherit hover:font-semibold select-none hover:underline" href="http://localhost:3000/#fig-open-source-workflow-output-evaluation" title="Link to this figure" aria-label="Link to this figure">Figure&nbsp;<!-- -->9<!-- -->:</a>18 FP were observed in the output produced using the open source workflow.</p></figcaption></figure><p>Knowing how many TP (18,736) there are in the benchmark output ultimately allows us to derive how many FP (18) and FN (65) there are in our workflow output and conduct our performance comparison.</p><figure id="tbl-performance-comparison" class="fig-table"><figcaption class="group"><p><a class="no-underline text-inherit hover:text-inherit mr-1 font-semibold text-inherit hover:text-inherit hover:font-semibold select-none hover:underline" href="http://localhost:3000/#tbl-performance-comparison" title="Link to this table" aria-label="Link to this table">Table&nbsp;<!-- -->1<!-- -->:</a>Performance Comparison</p></figcaption><table class=""><tbody><tr class=""><th class="text-center" rowspan="2">Workflow</th><th class="text-center" colspan="3">Detection Quality Metrics</th><th class="text-center" colspan="2">Localization Accuracy Metrics</th></tr><tr class=""><th class="text-center">Precision</th><th class="text-center">Recall</th><th class="text-center">F1 Score</th><th class="text-center">Mean Deviation (cm)</th><th class="text-center">IoU</th></tr><tr class=""><td class="text-center"><strong><em>Proprietary</em></strong></td><td class="text-center">0.9990</td><td class="text-center">1.0000</td><td class="text-center">0.9995</td><td class="text-center">1.39</td><td class="text-center">0.18</td></tr><tr class=""><td class="text-center"><strong><em>Open Source</em></strong></td><td class="text-center">0.9990</td><td class="text-center">0.9956</td><td class="text-center">0.9973</td><td class="text-center">1.20</td><td class="text-center">0.74</td></tr></tbody></table></figure><p>Having output geometry with real-world coordinates and QC geometry created based on the empirical observation that empty plant pots tend to be ~64 pixels wide and tall; QC points corresponding to actual pot centroids allowed us to create 64-by-64px boxes to facilitate our IoU calculations (see <a target="_blank" rel="noreferrer" href="https://colab.research.google.com/drive/1NqDTYw0V9yRnZtoT6Pc7ZJ3ATe7CTue8?usp=sharing#sandboxMode=true" class="">code</a>). These calculations further allow us to assess the relative alignment between the detection output geometry and our “ground truth” geometry.</p><p>This work makes it easy to identify down to the individual QC point ID level which detection centroids deviate from said point by more than 3 cm, which is the tolerance specified by our client. In aggregate, we are able to gain a quantified sense of the mean deviation (in cm) of the output produced by each workflow. However, visual inspection reveals that some QC points flagged as having cooresponding detection centroids that are out-of-tolerance were, in fact, themselves off-center. This is to say the some detections from both the open source workflow and the benchmark workflow were flagged as being out-of-tolerance when they observably were not.</p><figure id="fig-qc-point-91" class="fig-figure"><img id="rYj62fNqHA" style="margin:0 auto" src="./index_files/qc-point-91-collage-6e38bc8ea993f3396b106ab126ca5f7e.png" alt="Visual inspection of the detected centroids relative to QC point 91 reveal that the QC point is off-center." data-canonical-url="qc-point-91-collage.png"><figcaption class="group"><p><a class="no-underline text-inherit hover:text-inherit mr-1 font-semibold text-inherit hover:text-inherit hover:font-semibold select-none hover:underline" href="http://localhost:3000/#fig-qc-point-91" title="Link to this figure" aria-label="Link to this figure">Figure&nbsp;<!-- -->10<!-- -->:</a>Visual inspection of the detected centroids relative to QC point 91 reveal that the QC point is off-center.</p></figcaption></figure><p>Visual inspection also reveals that our detections (in pink) and those produced using the commercial software (in beige) have greater overall coverage with respect to the QC geometry (in grey). This provides intuition as to why the IoU calculations revealed a 400% increase in coverage with respect to the geometry produced using SAM’s automatic mask generator, zero-shot.</p><h2 id="discussion" class="relative group"><span class="mr-3 select-none">6</span><span class="heading-text">Discussion</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#discussion" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h2 id="conclusion" class="relative group"><span class="mr-3 select-none">7</span><span class="heading-text">Conclusion</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#conclusion" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>We present a robust, open source workflow for object detection and spatial localization in high-resolution drone orthomosaics, leveraging SAM’s zero-shot segmentation capabilities. Our quantitative evaluation demonstrates improved accuracy over a commercially available software solution, underscoring the potential of foundation models and open source tools to advance scalable, cost-effective feature extraction in agriculture. This work provides a template for further research and deployment in diverse contexts.</p><p>To our knowledge, this is the first comparative evaluation of an open source segmentation model (SAM) against commercial software in a context requiring high (&lt; 3 cm) spatial accuracy. Our results demonstrate that the workflow not only matches but in some cases exceeds performance metrics with respect to the evaluated output.</p><h2 id="conflicts-of-interest" class="relative group"><span class="mr-3 select-none">9</span><span class="heading-text">Conflicts of Interest</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#conflicts-of-interest" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The author declares no conflicts of interest.</p><h2 id="ai-usage-disclosure" class="relative group"><span class="mr-3 select-none">10</span><span class="heading-text">AI Usage Disclosure</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#ai-usage-disclosure" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>AI tools (ChatGPT, Perplexity, and NotebookLM) were used:</p><ul><li>in writing portions of the workflow integration code,</li><li>to generate Matplotlib subplots, process flow diagrams, <span class="" style="font-family:serif">L <span class="" style="vertical-align:0.4ex;font-size:0.8em">A</span> T <span class="" style="vertical-align:-0.3ex;font-size:0.8em">E</span> X</span>, etc.</li><li>for proofreading and light revision to reduce potential publication errors.</li></ul><h2 id="code" class="relative group"><span class="mr-3 select-none">11</span><span class="heading-text">Code</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#code" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p><a target="_blank" rel="noreferrer" href="https://github.com/nickmccarty/scipy-2025" class=""><img id="kQgOAhDLjA" style="margin:0 auto" src="./index_files/ec1d732ee9507693b3cf59f83e0e3fe8.svg" alt="GitHub" data-canonical-url="https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&amp;logo=github&amp;logoColor=white"></a>
<a target="_blank" rel="noreferrer" href="https://colab.research.google.com/drive/1pwnb14s2i7n_VAlfwhBqzDQ0cOb9oGs-?usp=sharing#sandboxMode=true" class=""><img id="vDGPxcv4OX" style="margin:0 auto" src="./index_files/7e2db436150c38a00650f96925aa5581.svg" alt="Open In Colab" data-canonical-url="https://colab.research.google.com/assets/colab-badge.svg"></a></p><h2 id="appendix-a" class="relative group"><span class="mr-3 select-none">12</span><span class="heading-text">Appendix A</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#appendix-a" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h3 id="accuracy-evaluation-methodology" class="relative group"><span class="mr-3 select-none">12.1</span><span class="heading-text">Accuracy Evaluation Methodology</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#accuracy-evaluation-methodology" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>The evaluation focuses on two primary categories of metrics: <em><strong>localization accuracy</strong></em> and <em><strong>detection quality</strong></em>; the employed methodology relies on the following data:</p><ul><li><strong>Ground Truth Quality Control (QC) Points</strong> (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>Q</mi><mi>C</mi></mrow></msub></mrow><annotation encoding="application/x-tex">P_{QC}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">QC</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span>), defined as a set of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mrow><mi>Q</mi><mi>C</mi></mrow></msub></mrow><annotation encoding="application/x-tex">N_{QC}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">QC</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span> known spatial coordinates, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>Q</mi><mi>C</mi></mrow></msub><mo>=</mo><mo stretchy="false">{</mo><msub><mi>p</mi><mi>j</mi></msub><msubsup><mo stretchy="false">}</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mrow><mi>Q</mi><mi>C</mi></mrow></msub></msubsup></mrow><annotation encoding="application/x-tex">P_{QC} = \{p_j\}_{j=1}^{N_{QC}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">QC</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4336em;vertical-align:-0.413em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0207em;"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2423em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">QC</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2822em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em;"><span></span></span></span></span></span></span></span></span></span></span>, where each <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>j</mi></msub><mo>=</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_j = (x_j, y_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> represents the centroid (in real-world coordinates) of our object of interest (empty plant pots), serving as the ground truth for spatial localization.</li><li><strong>Detected Object Centroids</strong> (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>D</mi><mi>e</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">C_{Det}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">De</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>) are used, which are a set of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mrow><mi>D</mi><mi>e</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">N_{Det}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">De</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> centroids, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>D</mi><mi>e</mi><mi>t</mi></mrow></msub><mo>=</mo><mo stretchy="false">{</mo><msub><mi>c</mi><mi>k</mi></msub><msubsup><mo stretchy="false">}</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mrow><mi>D</mi><mi>e</mi><mi>t</mi></mrow></msub></msubsup></mrow><annotation encoding="application/x-tex">C_{Det} = \{c_k\}_{k=1}^{N_{Det}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">De</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2247em;vertical-align:-0.3013em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9234em;"><span style="top:-2.3987em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.1451em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">De</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1433em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3013em;"><span></span></span></span></span></span></span></span></span></span></span>, where each <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>k</mi></msub><mo>=</mo><mo stretchy="false">(</mo><msubsup><mi>x</mi><mi>k</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo separator="true">,</mo><msubsup><mi>y</mi><mi>k</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">c_k = (x'_k, y'_k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.035em;vertical-align:-0.2831em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.4169em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.4169em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> is the centroid extracted from a polygon representing an object detected by the workflow.</li><li><strong>Detected Object Polygons</strong> (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mrow><mi>D</mi><mi>e</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">G_{Det}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">De</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>) are included, representing a set of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mrow><mi>D</mi><mi>e</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">N_{Det}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">De</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> polygons, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mrow><mi>D</mi><mi>e</mi><mi>t</mi></mrow></msub><mo>=</mo><mo stretchy="false">{</mo><msub><mi>g</mi><mi>k</mi></msub><msubsup><mo stretchy="false">}</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mrow><mi>D</mi><mi>e</mi><mi>t</mi></mrow></msub></msubsup><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">G_{Det} = \{g_k\}_{k=1}^{N_{Det}},</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">De</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2247em;vertical-align:-0.3013em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9234em;"><span style="top:-2.3987em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.1451em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">De</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1433em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3013em;"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span></span> where each <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>g</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">g_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> is a polygon generated from a SAM-produced mask after post-processing.</li><li><strong>Ground Truth Polygons</strong> (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mrow><mi>G</mi><mi>T</mi></mrow></msub></mrow><annotation encoding="application/x-tex">G_{GT}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">GT</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>) the calculation of Intersection over Union (IoU) implies the existence of a corresponding set of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mrow><mi>Q</mi><mi>C</mi></mrow></msub></mrow><annotation encoding="application/x-tex">N_{QC}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">QC</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span> ground truth polygons, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mrow><mi>G</mi><mi>T</mi></mrow></msub><mo>=</mo><mo stretchy="false">{</mo><msubsup><mi>g</mi><mi>j</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><msubsup><mo stretchy="false">}</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mrow><mi>Q</mi><mi>C</mi></mrow></msub></msubsup></mrow><annotation encoding="application/x-tex">G_{GT} = \{g'_j\}_{j=1}^{N_{QC}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">GT</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4336em;vertical-align:-0.413em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.4413em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0207em;"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2423em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">QC</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2822em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em;"><span></span></span></span></span></span></span></span></span></span></span>, where each <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>g</mi><mi>j</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">g'_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1467em;vertical-align:-0.3948em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.4413em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span></span></span></span></span> delineates the extent of the object associated with ground truth point <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">p_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span>. This allows for the quantification of the spatial alignment between the detection bounding boxes and those associated with the QC points, in aggregate. The provided <span data-state="closed"><a href="http://localhost:3000/#code" class="hover-link">code</a></span> details how we created this geometry and performed the calculations.</li></ul><div><div class="flex flex-col w-full md:flex-row group/backmatter"><h2 id="acknowledgments" class="mt-5 text-base font-semibold group md:w-[200px] self-start md:flex-none opacity-90 group-hover/backmatter:opacity-100">Acknowledgments<a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#acknowledgments" title="Link to Acknowledgments" aria-label="Link to Acknowledgments">¶</a></h2><div class="grow opacity-90 group-hover/backmatter:opacity-100 col-screen"><p>We gratefully acknowledge the contributions of the open source community — thank you to the giants on whose shoulders we stand.</p><p>This work was funded by FiOR Innovations and Woodburn Nursery &amp; Azaleas. We deeply appreciate their support and partnership.</p><p>Special thanks to Paniz Herrera, MBA, MSIST, for her invaluable suggestions.</p><p>We also thank Ryan Marinelli, PhD Fellow at the University of Oslo, for his assistance with proofreading and his insightful feedback.</p><p>Finally, to Danny Clifford, your insightful questions and targeted suggestions for improvement continue to be of tremendous value. Thank you.</p></div></div></div><section id="footnotes" class="article-left-grid subgrid-gap col-screen"><div><header class="text-lg font-semibold text-stone-900 dark:text-white group">Footnotes<a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#footnotes" title="Link to Footnotes" aria-label="Link to Footnotes">¶</a></header></div><div class="pl-3 mb-8 text-xs text-stone-500 dark:text-stone-300"><ol><li id="fn-footnote-1" class="group"><div class="flex flex-row"><div class="break-words grow"><p>Output evaluation details are discussed in <span data-state="closed"><a href="http://localhost:3000/#accuracy-evaluation-methodology" class="hover-link">Appendix A</a></span>.</p></div><div class="flex flex-col grow-0"><a class="no-underline text-inherit hover:text-inherit p-1 select-none [@media(hover:hover)]:transition-opacity [@media(hover:hover)]:opacity-0 [@media(hover:hover)]:focus:opacity-100 [@media(hover:hover)]:group-hover:opacity-70" href="http://localhost:3000/#fnref-LdJ8yuaTrF" title="Link to Content" aria-label="Link to Content">↩</a></div></div></li><li id="fn-footnote-2" class="group"><div class="flex flex-row"><div class="break-words grow"><p>See <a target="_blank" rel="noreferrer" href="https://raw.githubusercontent.com/nickmccarty/scipy-2025/refs/heads/main/requirements.txt" class="">requirements.txt</a> for version details.</p></div><div class="flex flex-col grow-0"><a class="no-underline text-inherit hover:text-inherit p-1 select-none [@media(hover:hover)]:transition-opacity [@media(hover:hover)]:opacity-0 [@media(hover:hover)]:focus:opacity-100 [@media(hover:hover)]:group-hover:opacity-70" href="http://localhost:3000/#fnref-eCEzLspsjq" title="Link to Content" aria-label="Link to Content">↩</a></div></div></li><li id="fn-footnote-3" class="group"><div class="flex flex-row"><div class="break-words grow"><p>Inference was accelerated using <code>CUDA 12</code> (<code>cuDF 25.2.1</code>) on a <code>T4</code> GPU within our Colab notebook environment.</p></div><div class="flex flex-col grow-0"><a class="no-underline text-inherit hover:text-inherit p-1 select-none [@media(hover:hover)]:transition-opacity [@media(hover:hover)]:opacity-0 [@media(hover:hover)]:focus:opacity-100 [@media(hover:hover)]:group-hover:opacity-70" href="http://localhost:3000/#fnref-r9Q5ldsRpN" title="Link to Content" aria-label="Link to Content">↩</a></div></div></li><li id="fn-footnote-4" class="group"><div class="flex flex-row"><div class="break-words grow"><p>We use open source QGIS <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://www.qgis.org/" target="_blank" rel="noreferrer" class="hover-link">QGIS Development Team, 2021</a></cite></span> as our selected data viewer.</p></div><div class="flex flex-col grow-0"><a class="no-underline text-inherit hover:text-inherit p-1 select-none [@media(hover:hover)]:transition-opacity [@media(hover:hover)]:opacity-0 [@media(hover:hover)]:focus:opacity-100 [@media(hover:hover)]:group-hover:opacity-70" href="http://localhost:3000/#fnref-Tfzo6FHqvW" title="Link to Content" aria-label="Link to Content">↩</a></div></div></li></ol></div></section><section id="references" class="article-left-grid subgrid-gap col-screen"><div><button class="float-right p-1 px-2 text-xs border rounded hover:border-blue-500 dark:hover:border-blue-400">Show All</button><header class="text-lg font-semibold text-stone-900 dark:text-white group">References<a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="http://localhost:3000/#references" title="Link to References" aria-label="Link to References">¶</a></header></div><div class="pl-3 mb-8 text-xs text-stone-500 dark:text-stone-300"><ol><li class="break-words" id="cite-wu23">Wu, Q., &amp; Osco, L. P. (2023). samgeo: A Python package for segmenting geospatial data with the Segment Anything Model (SAM). <i>Journal of Open Source Software</i>, <i>8</i>(89), 5663. <a target="_blank" rel="noreferrer" href="https://doi.org/10.21105/joss.05663">10.21105/joss.05663</a></li><li class="break-words" id="cite-osco23">Osco, L. P., Wu, Q., de Lemos, E. L., Gonçalves, W. N., Ramos, A. P. M., Li, J., &amp; Junior, J. M. (2023). <i>The Segment Anything Model (SAM) for Remote Sensing Applications: From Zero to One Shot</i>. <a target="_blank" rel="noreferrer" href="https://arxiv.org/abs/2306.16623">https://arxiv.org/abs/2306.16623</a></li><li class="break-words" id="cite-mayladan23">Mayladan, A., Nasrallah, H., Moughnieh, H., Shukor, M., &amp; Ghandour, A. J. (2024). <i>Zero-Shot Refinement of Buildings’ Segmentation Models using SAM</i>. <a target="_blank" rel="noreferrer" href="https://arxiv.org/abs/2310.01845">https://arxiv.org/abs/2310.01845</a></li><li class="break-words" id="cite-kirillov23">Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao, T., Whitehead, S., Berg, A. C., Lo, W.-Y., Dollár, P., &amp; Girshick, R. (2023). <i>Segment Anything</i>. <a target="_blank" rel="noreferrer" href="https://arxiv.org/abs/2304.02643">https://arxiv.org/abs/2304.02643</a></li><li class="break-words" id="cite-gdal">GDAL/OGR contributors. (2025). <i>GDAL/OGR Geospatial Data Abstraction software Library</i>. Open Source Geospatial Foundation. <a target="_blank" rel="noreferrer" href="https://doi.org/10.5281/zenodo.5884351">10.5281/zenodo.5884351</a></li><li class="break-words" id="cite-shapely">Gillies, S., van der Wel, C., Van den Bossche, J., Taves, M. W., Arnott, J., Ward, B. C., &amp; others. (2025). <i>Shapely (Version 2.1.1)</i>. <a target="_blank" rel="noreferrer" href="https://doi.org/10.5281/zenodo.5597138">10.5281/zenodo.5597138</a></li><li class="break-words" id="cite-geopandas">Jordahl, K., den Bossche, J. V., Fleischmann, M., Wasserman, J., McBride, J., Gerard, J., Tratner, J., Perry, M., Badaracco, A. G., Farmer, C., Hjelle, G. A., Snow, A. D., Cochran, M., Gillies, S., Culbertson, L., Bartos, M., Eubank, N., maxalbert, Bilogur, A., … Leblanc, F. (2020). <i>geopandas/geopandas: v0.8.1</i> (v0.8.1). Zenodo. <a target="_blank" rel="noreferrer" href="https://doi.org/10.5281/zenodo.3946761">10.5281/zenodo.3946761</a></li><li class="break-words" id="cite-rasterio">Gillies, S., &amp; others. (2013–). <i>Rasterio: geospatial raster I/O for Python programmers</i>. Mapbox. <a target="_blank" rel="noreferrer" href="https://github.com/rasterio/rasterio">https://github.com/rasterio/rasterio</a></li><li class="break-words" id="cite-matplotlib">Hunter, J. D. (2007). Matplotlib: A 2D graphics environment. <i>Computing in Science &amp; Engineering</i>, <i>9</i>(3), 90–95. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1109/MCSE.2007.55">https://doi.org/10.1109/MCSE.2007.55</a></li><li class="break-words" id="cite-numpy">Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., van Kerkwijk, M. H., Brett, M., Haldane, A., del Río, J. F., Wiebe, M., Peterson, P., … Oliphant, T. E. (2020). Array programming with NumPy. <i>Nature</i>, <i>585</i>(7825), 357–362. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1038/s41586-020-2649-2">https://doi.org/10.1038/s41586-020-2649-2</a></li><li class="break-words" id="cite-opencv">Bradski, G. (2000). The OpenCV Library. <i>Dr. Dobb’s Journal of Software Tools</i>.</li><li class="break-words" id="cite-openpyxl">Gazoni, E., &amp; Clark, C. (2024). <i>OpenPyXL: A Python library to read/write Excel 2010 xlsx/xlsm/xltx/xltm files</i>. Python Package. <a target="_blank" rel="noreferrer" href="https://openpyxl.readthedocs.io/">https://openpyxl.readthedocs.io</a></li><li class="break-words" id="cite-pandas1">The Pandas Development Team. (2020). <i>pandas-dev/pandas: Pandas</i> (latest). Zenodo. <a target="_blank" rel="noreferrer" href="https://doi.org/10.5281/zenodo.3509134">10.5281/zenodo.3509134</a></li><li class="break-words" id="cite-pandas2">McKinney, W. (2010). Data Structures for Statistical Computing in Python. In Stéfan van der Walt &amp; Jarrod Millman (Eds.), <i>Proceedings of the 9th Python in Science Conference</i> (pp. 56–61). <a target="_blank" rel="noreferrer" href="https://doi.org/10.25080/Majora-92bf1922-00a">https://doi.org/10.25080/Majora-92bf1922-00a</a></li><li class="break-words" id="cite-pillow">Clark, A. (2015). <i>Pillow (PIL Fork) Documentation</i>. readthedocs. <a target="_blank" rel="noreferrer" href="https://buildmedia.readthedocs.org/media/pdf/pillow/latest/pillow.pdf">https://buildmedia.readthedocs.org/media/pdf/pillow/latest/pillow.pdf</a></li><li class="text-center list-none"><button class="p-2 border rounded hover:border-blue-500 dark:hover:border-blue-400">Show all 17 references</button></li></ol></div></section></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/entry.client-MRWD3U4M.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-LBXIMZTV.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-UAI5KRM7.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-2NH4LW52.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-WXDXSPHK.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-HBJK6BW3.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-HYMQ7M2K.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-OHOXABTA.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-OCWQY3HK.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-CPTH56EW.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-3CVK3PYF.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-J6FHCSRC.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-S4SWV34C.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-GUCIBHGO.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/root-TE4XH6NL.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/_shared/chunk-KNCZRSA7.js"><link rel="modulepreload" href="http://localhost:3000/myst_assets_folder/routes/_index-GVPSY24U.js"><script>window.__remixContext = {"url":"/","state":{"loaderData":{"root":{"theme":"dark","config":{"version":2,"myst":"1.3.28","options":{},"nav":[],"actions":[],"projects":[{"date":"2025-07-10","open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"subject":"Research Article","numbering":{"heading_1":{"enabled":true},"heading_2":{"enabled":true},"heading_3":{"enabled":true},"heading_4":{"enabled":true},"heading_5":{"enabled":true},"heading_6":{"enabled":true}},"abbreviations":{"MyST":"Markedly Structured Text"},"exports":[],"downloads":[],"title":"Performing Object Detection on Drone Orthomosaics with Meta's Segment Anything Model (SAM)","description":"This article presents a workflow that utilizes SAM's automatic mask generation skill to effectively perform the task of object detection zero-shot on a high-resolution drone orthomosaic. The generated output is 20% more spatially accurate than that produced using proprietary software, with 400% greater IoU.","thumbnail":"http://localhost:3100/trimmer-cc850f3b5f2eb92884f6511d6db638c6.jpg","banner":"http://localhost:3100/banner-a36fcce9f637cecc37099063b2c3a3ae.png","authors":[{"nameParsed":{"literal":"Nicholas McCarty","given":"Nicholas","family":"McCarty"},"name":"Nicholas McCarty","orcid":"0009-0001-3727-9178","email":"nick@upskilled.consulting","affiliations":["Upskilled Consulting"],"id":"contributors-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-0","corresponding":true}],"editors":["hongsup","sanhita","rowan","charles","amey"],"contributors":[{"id":"hongsup","nameParsed":{"literal":"Hongsup Shin","given":"Hongsup","family":"Shin"},"name":"Hongsup Shin","email":"hongsup.shin@pm.me","affiliations":["Arm"]},{"id":"sanhita","nameParsed":{"literal":"Sanhita Joshi","given":"Sanhita","family":"Joshi"},"name":"Sanhita Joshi","email":"sanhita.joshi@gmail.com","affiliations":["Deloitte"]},{"id":"rowan","nameParsed":{"literal":"Rowan Cockett","given":"Rowan","family":"Cockett"},"name":"Rowan Cockett","email":"rowan@curvenote.com","affiliations":["affiliations-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-2"]},{"id":"charles","nameParsed":{"literal":"Charles Lindsey","given":"Charles","family":"Lindsey"},"name":"Charles Lindsey","email":"lindseycster@gmail.com","affiliations":["Aptos"]},{"id":"amey","nameParsed":{"literal":"Amey Ambade","given":"Amey","family":"Ambade"},"name":"Amey Ambade","email":"ameyambade@gmail.com","affiliations":["SLB"]}],"venue":{"title":"Python in Science Conference","short_title":"SciPy","url":"https://proceedings.scipy.org","doi":"10.25080/issn.2575-9752","number":"24rd","location":"Tacoma, Washington","date":"July ** - July **, 2025","series":"Proceedings of the Python in Science Conference","issn":"2575-9752","publisher":"SciPy"},"keywords":["object detection","spatial localization","drone orthomosaic"],"affiliations":[{"id":"Upskilled Consulting","name":"Upskilled Consulting"},{"id":"Arm","name":"Arm"},{"id":"Deloitte","name":"Deloitte"},{"name":"Curvenote","ror":"https://ror.org/02mz0e468","url":"https://curvenote.com","id":"affiliations-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-2"},{"id":"Aptos","name":"Aptos"},{"id":"SLB","name":"SLB"}],"id":"scipy-2025-nicholas_mccarty","bibliography":[],"index":"main","pages":[]}]},"CONTENT_CDN_PORT":"3100","MODE":"app"},"routes/_index":{"config":{"version":2,"myst":"1.3.28","options":{},"nav":[],"actions":[],"projects":[{"date":"2025-07-10","open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"subject":"Research Article","numbering":{"heading_1":{"enabled":true},"heading_2":{"enabled":true},"heading_3":{"enabled":true},"heading_4":{"enabled":true},"heading_5":{"enabled":true},"heading_6":{"enabled":true}},"abbreviations":{"MyST":"Markedly Structured Text"},"exports":[],"downloads":[],"title":"Performing Object Detection on Drone Orthomosaics with Meta's Segment Anything Model (SAM)","description":"This article presents a workflow that utilizes SAM's automatic mask generation skill to effectively perform the task of object detection zero-shot on a high-resolution drone orthomosaic. The generated output is 20% more spatially accurate than that produced using proprietary software, with 400% greater IoU.","thumbnail":"http://localhost:3100/trimmer-cc850f3b5f2eb92884f6511d6db638c6.jpg","banner":"http://localhost:3100/banner-a36fcce9f637cecc37099063b2c3a3ae.png","authors":[{"nameParsed":{"literal":"Nicholas McCarty","given":"Nicholas","family":"McCarty"},"name":"Nicholas McCarty","orcid":"0009-0001-3727-9178","email":"nick@upskilled.consulting","affiliations":["Upskilled Consulting"],"id":"contributors-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-0","corresponding":true}],"editors":["hongsup","sanhita","rowan","charles","amey"],"contributors":[{"id":"hongsup","nameParsed":{"literal":"Hongsup Shin","given":"Hongsup","family":"Shin"},"name":"Hongsup Shin","email":"hongsup.shin@pm.me","affiliations":["Arm"]},{"id":"sanhita","nameParsed":{"literal":"Sanhita Joshi","given":"Sanhita","family":"Joshi"},"name":"Sanhita Joshi","email":"sanhita.joshi@gmail.com","affiliations":["Deloitte"]},{"id":"rowan","nameParsed":{"literal":"Rowan Cockett","given":"Rowan","family":"Cockett"},"name":"Rowan Cockett","email":"rowan@curvenote.com","affiliations":["affiliations-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-2"]},{"id":"charles","nameParsed":{"literal":"Charles Lindsey","given":"Charles","family":"Lindsey"},"name":"Charles Lindsey","email":"lindseycster@gmail.com","affiliations":["Aptos"]},{"id":"amey","nameParsed":{"literal":"Amey Ambade","given":"Amey","family":"Ambade"},"name":"Amey Ambade","email":"ameyambade@gmail.com","affiliations":["SLB"]}],"venue":{"title":"Python in Science Conference","short_title":"SciPy","url":"https://proceedings.scipy.org","doi":"10.25080/issn.2575-9752","number":"24rd","location":"Tacoma, Washington","date":"July ** - July **, 2025","series":"Proceedings of the Python in Science Conference","issn":"2575-9752","publisher":"SciPy"},"keywords":["object detection","spatial localization","drone orthomosaic"],"affiliations":[{"id":"Upskilled Consulting","name":"Upskilled Consulting"},{"id":"Arm","name":"Arm"},{"id":"Deloitte","name":"Deloitte"},{"name":"Curvenote","ror":"https://ror.org/02mz0e468","url":"https://curvenote.com","id":"affiliations-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-2"},{"id":"Aptos","name":"Aptos"},{"id":"SLB","name":"SLB"}],"id":"scipy-2025-nicholas_mccarty","bibliography":[],"index":"main","pages":[]}]},"project":{"date":"2025-07-10","open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"subject":"Research Article","numbering":{"heading_1":{"enabled":true},"heading_2":{"enabled":true},"heading_3":{"enabled":true},"heading_4":{"enabled":true},"heading_5":{"enabled":true},"heading_6":{"enabled":true}},"abbreviations":{"MyST":"Markedly Structured Text"},"exports":[],"downloads":[],"title":"Performing Object Detection on Drone Orthomosaics with Meta's Segment Anything Model (SAM)","description":"This article presents a workflow that utilizes SAM's automatic mask generation skill to effectively perform the task of object detection zero-shot on a high-resolution drone orthomosaic. The generated output is 20% more spatially accurate than that produced using proprietary software, with 400% greater IoU.","thumbnail":"http://localhost:3100/trimmer-cc850f3b5f2eb92884f6511d6db638c6.jpg","banner":"http://localhost:3100/banner-a36fcce9f637cecc37099063b2c3a3ae.png","authors":[{"nameParsed":{"literal":"Nicholas McCarty","given":"Nicholas","family":"McCarty"},"name":"Nicholas McCarty","orcid":"0009-0001-3727-9178","email":"nick@upskilled.consulting","affiliations":["Upskilled Consulting"],"id":"contributors-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-0","corresponding":true}],"editors":["hongsup","sanhita","rowan","charles","amey"],"contributors":[{"id":"hongsup","nameParsed":{"literal":"Hongsup Shin","given":"Hongsup","family":"Shin"},"name":"Hongsup Shin","email":"hongsup.shin@pm.me","affiliations":["Arm"]},{"id":"sanhita","nameParsed":{"literal":"Sanhita Joshi","given":"Sanhita","family":"Joshi"},"name":"Sanhita Joshi","email":"sanhita.joshi@gmail.com","affiliations":["Deloitte"]},{"id":"rowan","nameParsed":{"literal":"Rowan Cockett","given":"Rowan","family":"Cockett"},"name":"Rowan Cockett","email":"rowan@curvenote.com","affiliations":["affiliations-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-2"]},{"id":"charles","nameParsed":{"literal":"Charles Lindsey","given":"Charles","family":"Lindsey"},"name":"Charles Lindsey","email":"lindseycster@gmail.com","affiliations":["Aptos"]},{"id":"amey","nameParsed":{"literal":"Amey Ambade","given":"Amey","family":"Ambade"},"name":"Amey Ambade","email":"ameyambade@gmail.com","affiliations":["SLB"]}],"venue":{"title":"Python in Science Conference","short_title":"SciPy","url":"https://proceedings.scipy.org","doi":"10.25080/issn.2575-9752","number":"24rd","location":"Tacoma, Washington","date":"July ** - July **, 2025","series":"Proceedings of the Python in Science Conference","issn":"2575-9752","publisher":"SciPy"},"keywords":["object detection","spatial localization","drone orthomosaic"],"affiliations":[{"id":"Upskilled Consulting","name":"Upskilled Consulting"},{"id":"Arm","name":"Arm"},{"id":"Deloitte","name":"Deloitte"},{"name":"Curvenote","ror":"https://ror.org/02mz0e468","url":"https://curvenote.com","id":"affiliations-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-2"},{"id":"Aptos","name":"Aptos"},{"id":"SLB","name":"SLB"}],"id":"scipy-2025-nicholas_mccarty","bibliography":[],"index":"main","pages":[]},"page":{"version":2,"kind":"Article","sha256":"2f086019da7c797e4d07226c09846c9913baf0461d9eefa470744d775f993147","slug":"main","location":"/main.md","dependencies":[],"frontmatter":{"title":"Performing Object Detection on Drone Orthomosaics with Meta's Segment Anything Model (SAM)","parts":{"abstract":{"mdast":{"type":"root","children":[{"type":"block","data":{"part":"abstract"},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Accurate and efficient object detection and spatial localization in remote sensing imagery is a persistent challenge. In the context of precision agriculture, the extensive data annotation required by conventional deep learning models poses additional challenges. This paper presents a fully open source workflow leveraging Meta AI’s Segment Anything Model (SAM) for zero-shot segmentation, enabling scalable object detection and spatial localization in high-resolution drone orthomosaics without the need for annotated image datasets. Model training and/or fine-tuning is rendered unnecessary in our precision agriculture-focused use case. The presented end-to-end workflow takes high-resolution images and quality control (QC) check points as inputs, automatically generates masks corresponding to the objects of interest (empty plant pots, in our given context), and outputs their spatial locations in real-world coordinates. Detection accuracy (required in the given context to be within 3 cm) is then quantitatively evaluated using the ground truth QC check points and benchmarked against object detection output generated using commercially available software. Results demonstrate that the open source workflow achieves superior spatial accuracy — producing output ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xWhFvGFJF5"},{"type":"inlineCode","value":"20% more spatially accurate","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"q0GLAOTH3u"},{"type":"text","value":", with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SRRRoUSBTk"},{"type":"inlineCode","value":"400% greater IoU","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DYJ8UolMOp"},{"type":"text","value":" — while providing a scalable way to perform spatial localization on high-resolution aerial imagery (with ground sampling distance, or GSD, \u003c 30 cm).","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"f0PmDzsYug"}],"key":"LZozGPEbQs"}],"key":"BaZGRJ4vyo"}],"key":"TBaEuniFfD"},"frontmatter":{"title":"Performing Object Detection on Drone Orthomosaics with Meta's Segment Anything Model (SAM)","authors":[{"nameParsed":{"literal":"Nicholas McCarty","given":"Nicholas","family":"McCarty"},"name":"Nicholas McCarty","orcid":"0009-0001-3727-9178","email":"nick@upskilled.consulting","affiliations":["Upskilled Consulting"],"id":"contributors-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-0","corresponding":true}],"editors":["hongsup","sanhita","rowan","charles","amey"],"date":"2025-07-10","open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"subject":"Research Article","venue":{"title":"Python in Science Conference","short_title":"SciPy","url":"https://proceedings.scipy.org","doi":"10.25080/issn.2575-9752","number":"24rd","location":"Tacoma, Washington","date":"July ** - July **, 2025","series":"Proceedings of the Python in Science Conference","issn":"2575-9752","publisher":"SciPy"},"numbering":{"heading_1":{"enabled":true},"heading_2":{"enabled":true},"heading_3":{"enabled":true},"heading_4":{"enabled":true},"heading_5":{"enabled":true},"heading_6":{"enabled":true}},"keywords":["object detection","spatial localization","drone orthomosaic"],"affiliations":[{"id":"Upskilled Consulting","name":"Upskilled Consulting"},{"id":"Arm","name":"Arm"},{"id":"Deloitte","name":"Deloitte"},{"name":"Curvenote","ror":"https://ror.org/02mz0e468","url":"https://curvenote.com","id":"affiliations-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-2"},{"id":"Aptos","name":"Aptos"},{"id":"SLB","name":"SLB"}],"contributors":[{"id":"hongsup","nameParsed":{"literal":"Hongsup Shin","given":"Hongsup","family":"Shin"},"name":"Hongsup Shin","email":"hongsup.shin@pm.me","affiliations":["Arm"]},{"id":"sanhita","nameParsed":{"literal":"Sanhita Joshi","given":"Sanhita","family":"Joshi"},"name":"Sanhita Joshi","email":"sanhita.joshi@gmail.com","affiliations":["Deloitte"]},{"id":"rowan","nameParsed":{"literal":"Rowan Cockett","given":"Rowan","family":"Cockett"},"name":"Rowan Cockett","email":"rowan@curvenote.com","affiliations":["affiliations-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-2"]},{"id":"charles","nameParsed":{"literal":"Charles Lindsey","given":"Charles","family":"Lindsey"},"name":"Charles Lindsey","email":"lindseycster@gmail.com","affiliations":["Aptos"]},{"id":"amey","nameParsed":{"literal":"Amey Ambade","given":"Amey","family":"Ambade"},"name":"Amey Ambade","email":"ameyambade@gmail.com","affiliations":["SLB"]}],"abbreviations":{"MyST":"Markedly Structured Text"}}}},"authors":[{"nameParsed":{"literal":"Nicholas McCarty","given":"Nicholas","family":"McCarty"},"name":"Nicholas McCarty","orcid":"0009-0001-3727-9178","email":"nick@upskilled.consulting","affiliations":["Upskilled Consulting"],"id":"contributors-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-0","corresponding":true}],"editors":["hongsup","sanhita","rowan","charles","amey"],"date":"2025-07-10","open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"subject":"Research Article","venue":{"title":"Python in Science Conference","short_title":"SciPy","url":"https://proceedings.scipy.org","doi":"10.25080/issn.2575-9752","number":"24rd","location":"Tacoma, Washington","date":"July ** - July **, 2025","series":"Proceedings of the Python in Science Conference","issn":"2575-9752","publisher":"SciPy"},"numbering":{"heading_1":{"enabled":true},"heading_2":{"enabled":true},"heading_3":{"enabled":true},"heading_4":{"enabled":true},"heading_5":{"enabled":true},"heading_6":{"enabled":true}},"keywords":["object detection","spatial localization","drone orthomosaic"],"affiliations":[{"id":"Upskilled Consulting","name":"Upskilled Consulting"},{"id":"Arm","name":"Arm"},{"id":"Deloitte","name":"Deloitte"},{"name":"Curvenote","ror":"https://ror.org/02mz0e468","url":"https://curvenote.com","id":"affiliations-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-2"},{"id":"Aptos","name":"Aptos"},{"id":"SLB","name":"SLB"}],"contributors":[{"id":"hongsup","nameParsed":{"literal":"Hongsup Shin","given":"Hongsup","family":"Shin"},"name":"Hongsup Shin","email":"hongsup.shin@pm.me","affiliations":["Arm"]},{"id":"sanhita","nameParsed":{"literal":"Sanhita Joshi","given":"Sanhita","family":"Joshi"},"name":"Sanhita Joshi","email":"sanhita.joshi@gmail.com","affiliations":["Deloitte"]},{"id":"rowan","nameParsed":{"literal":"Rowan Cockett","given":"Rowan","family":"Cockett"},"name":"Rowan Cockett","email":"rowan@curvenote.com","affiliations":["affiliations-Users\\nicho\\Desktop\\scipy_proceedings\\papers\\nicholas_mccarty\\myst-generated-uid-2"]},{"id":"charles","nameParsed":{"literal":"Charles Lindsey","given":"Charles","family":"Lindsey"},"name":"Charles Lindsey","email":"lindseycster@gmail.com","affiliations":["Aptos"]},{"id":"amey","nameParsed":{"literal":"Amey Ambade","given":"Amey","family":"Ambade"},"name":"Amey Ambade","email":"ameyambade@gmail.com","affiliations":["SLB"]}],"abbreviations":{"MyST":"Markedly Structured Text"},"thumbnail":"http://localhost:3100/trimmer-cc850f3b5f2eb92884f6511d6db638c6.jpg","exports":[{"format":"md","filename":"main.md","url":"http://localhost:3100/main-bdf2619ee6c07b3f8518f275fc0948d6.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Introduction","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"wAmmAm4y2C"}],"identifier":"introduction","label":"Introduction","html_id":"introduction","implicit":true,"enumerator":"1","key":"ovv8v7jGGb"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Image segmentation is a critical task in geospatial analysis, enabling the identification and extraction of relevant features from high resolution remote sensing imagery ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"F2SunkqNvF"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"cite","identifier":"wu23","label":"wu23","kind":"parenthetical","position":{"start":{"line":10,"column":172},"end":{"line":10,"column":177}},"children":[{"type":"text","value":"Wu \u0026 Osco, 2023","key":"ry869cvLDW"}],"enumerator":"1","key":"MTYgbP34YU"}],"key":"rS2AcNt6r3"},{"type":"text","value":". However, extracting actionable information (i.e., object detection and spatial localization) can be constrained by the need for large, labeled datasets to train deep learning models in order to then perform inference and (hopefully) produce the desired output. This bottleneck is particularly acute in agricultural domains, where variability in conditions and object types complicates manual annotation ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"rxH7BkDWKa"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"cite","identifier":"osco23","label":"osco23","kind":"parenthetical","position":{"start":{"line":10,"column":584},"end":{"line":10,"column":591}},"children":[{"type":"text","value":"Osco ","key":"jf50PjlsCN"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"MCScGdxQv6"}],"key":"oh5GlrlT9P"},{"type":"text","value":", 2023","key":"V2aguLF001"}],"enumerator":"2","key":"axXZpBFbty"}],"key":"p4ofl9olaS"},{"type":"text","value":".","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"YJk5lzQI0n"}],"key":"aSadY6dNiL"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Recent advances in foundation models, such as Meta AI’s Segment Anything Model (SAM), offer a promising path forward. SAM is designed for promptable “zero-shot” segmentation. “Prompt engineering”, in this context, involves using points and bounding boxes to focus the model’s efforts on more efficiently generating masks corresponding to objects of interest ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"qZ9iQvC9KW"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"cite","identifier":"mayladan23","label":"mayladan23","kind":"parenthetical","position":{"start":{"line":12,"column":360},"end":{"line":12,"column":371}},"children":[{"type":"text","value":"Mayladan ","key":"Z2Ot6qgCL4"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"UFawqnBr5i"}],"key":"Odmh7sccaw"},{"type":"text","value":", 2024","key":"hgh13UZWd0"}],"enumerator":"3","key":"tb1Y0tUtNE"}],"key":"gDZAcs3LZC"},{"type":"text","value":". Providing these prompts allows accurate masks to be generated for novel objects (ones not included in SAM’s training corpus), without domain-specific training. Masks can also be generated automatically with no such prompting. SAM’s automatic mask generator will effectively “detect” everything using open source model checkpoints and generate masks for each object in a provided image ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"csbW3M1UkV"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"cite","identifier":"kirillov23","label":"kirillov23","kind":"parenthetical","position":{"start":{"line":12,"column":760},"end":{"line":12,"column":771}},"children":[{"type":"text","value":"Kirillov ","key":"jDzhIqBf1X"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"D4PB6GkUik"}],"key":"Zahp9hODUf"},{"type":"text","value":", 2023","key":"hfQh08LL8N"}],"enumerator":"4","key":"ld2D3FeJXN"}],"key":"Xslr1LS4uH"},{"type":"text","value":".","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"vfVjMmv69a"}],"key":"gPy9WM0Q0a"},{"type":"paragraph","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"While SAM’s ability to generalize is impressive ","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"JsbM8fbbEi"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"cite","identifier":"kirillov23","label":"kirillov23","kind":"parenthetical","position":{"start":{"line":14,"column":50},"end":{"line":14,"column":61}},"children":[{"type":"text","value":"Kirillov ","key":"sysB38otTH"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"wFM17c3ep3"}],"key":"yBjHa6f9Dj"},{"type":"text","value":", 2023","key":"l3BPgW960D"}],"enumerator":"4","key":"Dmsq71QsFv"},{"type":"cite","identifier":"osco23","label":"osco23","kind":"parenthetical","position":{"start":{"line":14,"column":62},"end":{"line":14,"column":70}},"children":[{"type":"text","value":"Osco ","key":"PU7TAVWqrV"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"MlVbDkV6db"}],"key":"u2sIpCtlRr"},{"type":"text","value":", 2023","key":"UABtY7JE4y"}],"enumerator":"2","key":"vdqziLyzBA"}],"key":"jqdngMZJkv"},{"type":"text","value":", its performance on remote sensing imagery and fine-grained features requires careful workflow integration and evaluation ","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"LB7jwHBaFz"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"cite","identifier":"wu23","label":"wu23","kind":"parenthetical","position":{"start":{"line":14,"column":195},"end":{"line":14,"column":200}},"children":[{"type":"text","value":"Wu \u0026 Osco, 2023","key":"ehUJ9uF39F"}],"enumerator":"1","key":"UVNRm7a1PT"}],"key":"FFj8nyl54T"},{"type":"text","value":". This paper describes a comprehensive, open source workflow for object detection and spatial localization in high-resolution remote sensing imagery, built around SAM and widely used geospatial Python libraries ","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"m8Lsf7Y9lp"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"cite","identifier":"gdal","label":"gdal","kind":"parenthetical","position":{"start":{"line":14,"column":413},"end":{"line":14,"column":418}},"children":[{"type":"text","value":"GDAL/OGR contributors, 2025","key":"sayGRDi8t6"}],"enumerator":"5","key":"QLzjzd19nl"},{"type":"cite","identifier":"shapely","label":"shapely","kind":"parenthetical","position":{"start":{"line":14,"column":419},"end":{"line":14,"column":428}},"children":[{"type":"text","value":"Gillies ","key":"swR7f01uoB"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"aHOR7mzdu7"}],"key":"fiekCXhtAj"},{"type":"text","value":", 2025","key":"hQprLNWpbZ"}],"enumerator":"6","key":"jqtbKMY21F"},{"type":"cite","identifier":"geopandas","label":"geopandas","kind":"parenthetical","position":{"start":{"line":14,"column":429},"end":{"line":14,"column":440}},"children":[{"type":"text","value":"Jordahl ","key":"tfwejxJoYS"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"P7ajArBu4X"}],"key":"WOhRK7bmlp"},{"type":"text","value":", 2020","key":"TouJnW5u5W"}],"enumerator":"7","key":"Hp3rFBzp3b"},{"type":"cite","identifier":"rasterio","label":"rasterio","kind":"parenthetical","position":{"start":{"line":14,"column":441},"end":{"line":14,"column":451}},"children":[{"type":"text","value":"Gillies \u0026 others, 2013","key":"ksUDEhSb7Y"}],"enumerator":"8","key":"BiFz32fDJl"}],"key":"alHcS3HfsI"},{"type":"text","value":". The complete process is delineated, from data loading and preprocessing to mask generation, post-processing, and quantitative accuracy assessment, culminating in a robust comparison with the results produced using the proprietary software (see ","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"onXheuKNoO"},{"type":"crossReference","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"code","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"yFD3WdmQS3"}],"identifier":"code","label":"code","kind":"heading","template":"Section %s","enumerator":"11","resolved":true,"html_id":"code","key":"V4RjHFymfs"},{"type":"text","value":"). Precision, accuracy, F1 score, mean deviation (in cm), and Intersection-over-Union (IoU) are calculated in order to quantify the relative quality of the output produced using each workflow","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"X6HuyI6WZb"},{"type":"footnoteReference","identifier":"footnote-1","label":"footnote-1","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"enumerator":"1","key":"LdJ8yuaTrF"},{"type":"text","value":".","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"m3yCLpx5g4"}],"key":"zGVMkm9LTr"},{"type":"heading","depth":2,"position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Motivation","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"Hjrr0k8mCw"}],"identifier":"motivation","label":"Motivation","html_id":"motivation","implicit":true,"enumerator":"2","key":"WYEM2NkRJq"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Precision agriculture relies on accurate object detection for tasks such as plant counting, health monitoring, and targeted resource distribution. Traditional deep learning approaches can become hindered by the cost and effort of generating carefully annotated data, limiting scalability and accessibility. Proprietary solutions, while effective, can be expensive and opaque, impeding reproducibility and customization.","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"QcWBZ1vdAg"}],"key":"lkVXdprhgE"},{"type":"container","kind":"figure","children":[{"type":"image","url":"http://localhost:3100/trimmer-cc850f3b5f2eb92884f6511d6db638c6.jpg","alt":"The derived centroids of the objects detected in the drone orthomosaic are used to automate this nursery trimmer.","data":{"altTextIsAutoGenerated":true},"key":"xMBO3qtJqg","urlSource":"trimmer.jpg"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"captionNumber","kind":"figure","label":"fig:trimmer","identifier":"fig:trimmer","html_id":"fig-trimmer","enumerator":"1","children":[{"type":"text","value":"Figure ","key":"mcydaKHbYb"},{"type":"text","value":"1","key":"hDGOXtvXv2"},{"type":"text","value":":","key":"ecvGWkNGf5"}],"template":"Figure %s:","key":"nLhKx9CRnW"},{"type":"text","value":"The derived centroids of the objects detected in the drone orthomosaic are used to automate this nursery trimmer.","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"CEZFSHoJdj"}],"key":"wlOQBVUudl"}],"key":"hgq1s5Cjqc"}],"label":"fig:trimmer","identifier":"fig:trimmer","enumerator":"1","html_id":"fig-trimmer","key":"m7n33x9YoR"},{"type":"paragraph","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"SAM’s zero-shot segmentation capability directly addresses the data annotation bottleneck, enabling rapid deployment in novel contexts. By developing an open source workflow around SAM, an end-to-end pipeline is created which allows for the quantitative evaluation of spatial accuracy with respect to objects detected in high-resolution aerial imagery. This modular workflow can also be repurposed as an automated data annotation pipeline for downstream model training/fine-tuning, if required.","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"ges7Akd7Hn"}],"key":"Zp0knKSrNk"},{"type":"heading","depth":2,"position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"Approach","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"PaPr9UfvfS"}],"identifier":"approach","label":"Approach","html_id":"approach","implicit":true,"enumerator":"3","key":"uxBOcxi7nK"},{"type":"paragraph","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"Our approach integrates SAM’s segmentation strengths with traditional geospatial data processing techniques, which lends itself to our precision agriculture use case. The workflow, like any other, can be thought of as a sequence of steps (visualized above and described below), each with their own sets of substeps:","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"RYMxcJR45O"}],"key":"oNtedtccIO"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":34,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"strong","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"Data Ingestion","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"oBKXo0xPIG"}],"key":"WECi9pCQKn"},{"type":"text","value":": Loading GeoTIFF orthomosaics and QC point CSVs, extracting spatial bounds and coordinate reference systems (CRS) using Rasterio or GDAL.","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"W7gKXxXfYD"}],"key":"dvoHmwJHT9"},{"type":"listItem","spread":true,"position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"strong","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"Preprocessing","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"EjebrIFy4L"}],"key":"Gf4PoobcYF"},{"type":"text","value":": Filtering QC points to those within image bounds, standardizing coordinate columns, and saving filtered data for downstream analysis.","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"wha0djhuFi"}],"key":"CfS573BkBX"},{"type":"listItem","spread":true,"position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"strong","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"Mask Generation","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"eqiarzu9Ry"}],"key":"DxLcYv8iZh"},{"type":"text","value":": Tiling large images for efficient processing, running SAM’s automatic mask generator (","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"O45WueFge7"},{"type":"strong","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"ViT-H","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"PLy9cqGY5a"}],"key":"kOSaq3iZZi"}],"key":"QPvP1MX7Tx"},{"type":"text","value":" variant) on each tile, and filtering masks by confidence.","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"EcB9kHs1IE"}],"key":"ujLhKtbgB0"},{"type":"listItem","spread":true,"position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"strong","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"Post-Processing","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"k8kymGUlNX"}],"key":"Eo8WdFOULg"},{"type":"text","value":": Converting masks to polygons, filtering by area and compactness, merging overlapping geometry, and extracting centroids.","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"AhRxaOPz3D"}],"key":"ZIuNXmlj74"},{"type":"listItem","spread":true,"position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"strong","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"Accuracy Evaluation","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"tGy8y9JoKh"}],"key":"v1dkWoZf1v"},{"type":"text","value":": Calculating point-to-centroid deviations (in centimeters) between detected objects and QC points, compiling results, and generating visual and tabular reports.","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"y5z4hsSBVT"}],"key":"gOZJts1ZwD"},{"type":"listItem","spread":true,"position":{"start":{"line":39,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"strong","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"Benchmarking","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"Qh61DfoUfx"}],"key":"oNdyOIBal7"},{"type":"text","value":": Quantitatively comparing SAM-based results against the evaluated output using identical evaluation metrics (precision, recall, IoU, etc.; see ","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"MCWPN5cVub"},{"type":"crossReference","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"Appendix A","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"HojMNoHF2r"}],"identifier":"accuracy-evaluation-methodology","label":"accuracy-evaluation-methodology","kind":"heading","template":"Section %s","enumerator":"12.1","resolved":true,"html_id":"accuracy-evaluation-methodology","key":"xb1oQ9AgzW"},{"type":"text","value":" for details).","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"BXCuWXGpWC"}],"key":"mUYe7OgMhU"}],"key":"Bqm7AkiuHZ"},{"type":"paragraph","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"text","value":"It should be noted that there are no model training or fine-tuning steps included in our workflow, as we are using a foundation model to generate masks. This is analogous to using ChatGPT to generate text, which does not require users to train or fine-tune the underlying foundation model in order to do so.","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"wUumqkUcU2"}],"key":"SPbAFZp3Dy"},{"type":"paragraph","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"text","value":"This approach is carried out entirely using open source Python libraries, ensuring transparency and extensibility.","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"DGxj5DOSLx"}],"key":"PnQSsmj5OA"},{"type":"heading","depth":2,"position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"text","value":"Methodology","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"JvsKg1qD70"}],"identifier":"methodology","label":"Methodology","html_id":"methodology","implicit":true,"enumerator":"4","key":"ivveP41I94"},{"type":"heading","depth":3,"position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"Data and Environment","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"xcYmNbD7Ti"}],"identifier":"data-and-environment","label":"Data and Environment","html_id":"data-and-environment","implicit":true,"enumerator":"4.1","key":"kKvJHBuqGa"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":49,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":49,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"strong","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"Imagery","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"wTNijrw5LW"}],"key":"wjkmH55oVl"},{"type":"text","value":": High-resolution GeoTIFF orthomosaic.","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"F05HybJKgs"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":50,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"children":[{"type":"strong","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"children":[{"type":"text","value":"Image size","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"AsXGIaDm9J"}],"key":"DM6L0gapaA"},{"type":"text","value":": 18,200 x 55,708; 1,013,885,600 pixels","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"q1gbeZe1r5"}],"key":"HGEfH8Gn5Y"},{"type":"listItem","spread":true,"position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"children":[{"type":"strong","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"children":[{"type":"text","value":"Total area","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"key":"s5tsYIQILB"}],"key":"IQcttaZoId"},{"type":"text","value":": 545,243 sq ft; 12.5 acres","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"key":"sr40zQY8VG"}],"key":"bKSQhO7KGc"},{"type":"listItem","spread":true,"position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"strong","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"GSD","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"Ne2hPacxiT"}],"key":"VwATeezc68"},{"type":"text","value":": 0.71 cm","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"mEL49zeqoX"}],"key":"SnOslOJQYM"}],"key":"z5Yv4FeyaX"}],"key":"COo5492GxI"},{"type":"listItem","spread":true,"position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"children":[{"type":"strong","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"children":[{"type":"text","value":"Ground Truth","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"g41o2MeBNQ"}],"key":"AviplXkibP"},{"type":"text","value":": QC points in CSV format, containing spatial coordinates and unique identifiers.","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"fHWZ4z1BCf"}],"key":"iWWSmnZdnl"},{"type":"listItem","spread":true,"position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"children":[{"type":"strong","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"children":[{"type":"text","value":"Coordinate Reference System (CRS) Transformations","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"KthcI0uQIt"}],"key":"RibBDJaqA5"},{"type":"text","value":": All spatial operations are performed using the NAD83 CRS (EPSG:6859), with reprojection to the WGS84 CRS (EPSG:4326) for downstream reporting and nursery trimmer automation.","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"HxpYmTRmJe"}],"key":"TfKC5fV6mZ"},{"type":"listItem","spread":true,"position":{"start":{"line":55,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"strong","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"text","value":"Dependencies","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"key":"gInaucj4Og"}],"key":"f3NDk5jPn1"},{"type":"footnoteReference","identifier":"footnote-2","label":"footnote-2","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"enumerator":"2","key":"eCEzLspsjq"},{"type":"text","value":":","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"key":"G6woVeM7oX"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":56,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"children":[{"type":"text","value":"GDAL ","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"oHgtvW6QYa"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"children":[{"type":"cite","identifier":"gdal","label":"gdal","kind":"parenthetical","position":{"start":{"line":56,"column":7},"end":{"line":56,"column":12}},"children":[{"type":"text","value":"GDAL/OGR contributors, 2025","key":"ozOmzTk49g"}],"enumerator":"5","key":"nFJgWw7gx2"}],"key":"sbZhiYyQiY"}],"key":"sg5kwSVUIT"},{"type":"listItem","spread":true,"position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"text","value":"GeoPandas ","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"W74gjKGxks"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"cite","identifier":"geopandas","label":"geopandas","kind":"parenthetical","position":{"start":{"line":57,"column":12},"end":{"line":57,"column":22}},"children":[{"type":"text","value":"Jordahl ","key":"LW5XwgXO1d"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"Q5OEmtE7Hm"}],"key":"ygeGdO7HnS"},{"type":"text","value":", 2020","key":"TFlvSqbWfo"}],"enumerator":"7","key":"A74ls6jgh1"}],"key":"nv9KPVJeOW"}],"key":"k5wFNHxWRk"},{"type":"listItem","spread":true,"position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"text","value":"Matplotlib ","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"i9sPIJK5Mt"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"cite","identifier":"matplotlib","label":"matplotlib","kind":"parenthetical","position":{"start":{"line":58,"column":13},"end":{"line":58,"column":24}},"children":[{"type":"text","value":"Hunter, 2007","key":"kMbYZUqjEq"}],"enumerator":"9","key":"FSC0VtNCNS"}],"key":"sDXIXe8mZY"}],"key":"mqBb6nLnBh"},{"type":"listItem","spread":true,"position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"children":[{"type":"text","value":"NumPy ","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"fhfYlc7Dca"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"children":[{"type":"cite","identifier":"numpy","label":"numpy","kind":"parenthetical","position":{"start":{"line":59,"column":8},"end":{"line":59,"column":14}},"children":[{"type":"text","value":"Harris ","key":"CnV3kWpjfr"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"blEODqtAkC"}],"key":"eRI50tMEFs"},{"type":"text","value":", 2020","key":"DRxJ5snNdK"}],"enumerator":"10","key":"NQ0GkxqgaF"}],"key":"BjR1g7obfr"}],"key":"D276CNlAru"},{"type":"listItem","spread":true,"position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"text","value":"OpenCV ","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"qa1f5LZuf5"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"cite","identifier":"opencv","label":"opencv","kind":"parenthetical","position":{"start":{"line":60,"column":9},"end":{"line":60,"column":16}},"children":[{"type":"text","value":"Bradski, 2000","key":"gBmNC1FjB2"}],"enumerator":"11","key":"QfJxtcygBq"}],"key":"H1aO501aW1"}],"key":"wAJ9oRynPP"},{"type":"listItem","spread":true,"position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"children":[{"type":"text","value":"OpenPyXL ","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"vXAV8LOjlQ"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"children":[{"type":"cite","identifier":"openpyxl","label":"openpyxl","kind":"parenthetical","position":{"start":{"line":61,"column":11},"end":{"line":61,"column":20}},"children":[{"type":"text","value":"Gazoni \u0026 Clark, 2024","key":"g0W3qGZI4d"}],"enumerator":"12","key":"mywiBdTWxv"}],"key":"v6SgvZPBLy"}],"key":"MN97OBpNMe"},{"type":"listItem","spread":true,"position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"text","value":"Pandas ","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"b4Xva9O5vO"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"cite","identifier":"pandas1","label":"pandas1","kind":"parenthetical","position":{"start":{"line":62,"column":9},"end":{"line":62,"column":17}},"children":[{"type":"text","value":"The Pandas Development Team, 2020","key":"MSmuNJQ9ZJ"}],"enumerator":"13","key":"UfIohctgtE"},{"type":"cite","identifier":"pandas2","label":"pandas2","kind":"parenthetical","position":{"start":{"line":62,"column":18},"end":{"line":62,"column":27}},"children":[{"type":"text","value":"McKinney, 2010","key":"Tb9tVa1cEe"}],"enumerator":"14","key":"fVjL8vz6uF"}],"key":"xkkIgpUBWu"}],"key":"A14n9cCGoq"},{"type":"listItem","spread":true,"position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"text","value":"Pillow ","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"FuDJRBgqKx"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"cite","identifier":"pillow","label":"pillow","kind":"parenthetical","position":{"start":{"line":63,"column":9},"end":{"line":63,"column":16}},"children":[{"type":"text","value":"Clark, 2015","key":"SW0bCkCeBD"}],"enumerator":"15","key":"kZ9QSoxdoL"}],"key":"mlum9Lt1Jf"}],"key":"tvziafT6fC"},{"type":"listItem","spread":true,"position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"children":[{"type":"text","value":"Rasterio ","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"key":"TCGQZF0pO9"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"children":[{"type":"cite","identifier":"rasterio","label":"rasterio","kind":"parenthetical","position":{"start":{"line":64,"column":11},"end":{"line":64,"column":20}},"children":[{"type":"text","value":"Gillies \u0026 others, 2013","key":"jCmc5Mpcn6"}],"enumerator":"8","key":"KDmjzgK7tX"}],"key":"D6UQIO6MCu"}],"key":"ofWOKJ5lHe"},{"type":"listItem","spread":true,"position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"children":[{"type":"text","value":"Segment Anything","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"hjUqLXeXX7"},{"type":"footnoteReference","identifier":"footnote-3","label":"footnote-3","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"enumerator":"3","key":"r9Q5ldsRpN"},{"type":"text","value":" ","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"XCCP5C7NhM"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"children":[{"type":"cite","identifier":"kirillov23","label":"kirillov23","kind":"parenthetical","position":{"start":{"line":65,"column":32},"end":{"line":65,"column":43}},"children":[{"type":"text","value":"Kirillov ","key":"YywxKZ54nY"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"U4vP7tE1av"}],"key":"hlihvgPxq2"},{"type":"text","value":", 2023","key":"lz7yLTYACE"}],"enumerator":"4","key":"cD9YIy73H1"}],"key":"XITgGGHyZE"}],"key":"yugsOdydLa"},{"type":"listItem","spread":true,"position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"text","value":"Shapely ","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"yy4cEZ0CyS"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"cite","identifier":"shapely","label":"shapely","kind":"parenthetical","position":{"start":{"line":66,"column":10},"end":{"line":66,"column":18}},"children":[{"type":"text","value":"Gillies ","key":"GbOWz9iF1V"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"drfz3ktjed"}],"key":"zQW8Qtcl6t"},{"type":"text","value":", 2025","key":"tKGuVXRVNu"}],"enumerator":"6","key":"hf3IndAIA6"}],"key":"FKCoAJ3Gpv"}],"key":"FXdqZKrZwB"},{"type":"listItem","spread":true,"position":{"start":{"line":67,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"text","value":"Torch ","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"wfUGsV4I0l"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"cite","identifier":"pytorch","label":"pytorch","kind":"parenthetical","position":{"start":{"line":67,"column":8},"end":{"line":67,"column":16}},"children":[{"type":"text","value":"Paszke ","key":"oldetVDmR9"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"lyS4qUKUVB"}],"key":"WRRgDCIHNz"},{"type":"text","value":", 2019","key":"GRN0edPCTH"}],"enumerator":"16","key":"Z9nUGqDG0F"}],"key":"VAUJbvEuC9"}],"key":"b8Sctnd4xE"}],"key":"cRTsqxvpdk"}],"key":"bpyQvSi6pc"}],"key":"sXWfiPIzVl"},{"type":"heading","depth":3,"position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"children":[{"type":"text","value":"Workflow","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"key":"bZ9k3kxqaf"}],"identifier":"workflow","label":"Workflow","html_id":"workflow","implicit":true,"enumerator":"4.2","key":"p0MFpsOyJE"},{"type":"container","kind":"figure","children":[{"type":"image","url":"http://localhost:3100/workflow-af7b467f0709fce0583142963a37004f.png","alt":"The high-level workflow steps.","data":{"altTextIsAutoGenerated":true},"key":"rdq0CEZ0zC","urlSource":"workflow.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"children":[{"type":"captionNumber","kind":"figure","label":"fig:workflow","identifier":"fig:workflow","html_id":"fig-workflow","enumerator":"2","children":[{"type":"text","value":"Figure ","key":"t8dw9MEGIK"},{"type":"text","value":"2","key":"Mx8l6ytYsD"},{"type":"text","value":":","key":"LL7FksaUcm"}],"template":"Figure %s:","key":"K9e71fsZot"},{"type":"text","value":"The high-level workflow steps.","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"fDsKjrljE3"}],"key":"iP5Gz7JmJs"}],"key":"dAXwD1FA6g"}],"label":"fig:workflow","identifier":"fig:workflow","enumerator":"2","html_id":"fig-workflow","key":"SLD1wQBMZR"},{"type":"heading","depth":4,"position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"children":[{"type":"text","value":"Data Ingestion and Preprocessing","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"key":"fthinMReKg"}],"identifier":"data-ingestion-and-preprocessing","label":"Data Ingestion and Preprocessing","html_id":"data-ingestion-and-preprocessing","implicit":true,"enumerator":"4.2.1","key":"gvDmareSz4"},{"type":"container","kind":"figure","children":[{"type":"image","url":"http://localhost:3100/ingestion-and-prepro-5dd37aadcfd09656ee0ff07de3b097af.png","alt":"Data ingestion and preprocessing workflow substeps.","data":{"altTextIsAutoGenerated":true},"key":"dDCnwkInZw","urlSource":"ingestion-and-preprocessing.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"children":[{"type":"captionNumber","kind":"figure","label":"fig:ingestion-and-preprocessing","identifier":"fig:ingestion-and-preprocessing","html_id":"fig-ingestion-and-preprocessing","enumerator":"3","children":[{"type":"text","value":"Figure ","key":"tx5d9V8Q9i"},{"type":"text","value":"3","key":"izQ0nXwKYC"},{"type":"text","value":":","key":"dCs547zLYe"}],"template":"Figure %s:","key":"rbNK5WBZd7"},{"type":"text","value":"Data ingestion and preprocessing workflow substeps.","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"key":"QsDrnzOyAJ"}],"key":"COi3kz3bdH"}],"key":"rDz0aJ0w5F"}],"label":"fig:ingestion-and-preprocessing","identifier":"fig:ingestion-and-preprocessing","enumerator":"3","html_id":"fig-ingestion-and-preprocessing","key":"jXkNzzcvtQ"},{"type":"heading","depth":4,"position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"children":[{"type":"text","value":"Mask Generation","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"key":"N7Yg4fniiV"}],"identifier":"mask-generation","label":"Mask Generation","html_id":"mask-generation","implicit":true,"enumerator":"4.2.2","key":"WkzRZACzYU"},{"type":"container","kind":"figure","children":[{"type":"image","url":"http://localhost:3100/mask-generation-6063d070d6220423919c6d106fec241c.png","alt":"Mask generation workflow substeps.","data":{"altTextIsAutoGenerated":true},"key":"sO3rBzaKNu","urlSource":"mask-generation.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":91,"column":1},"end":{"line":91,"column":1}},"children":[{"type":"captionNumber","kind":"figure","label":"fig:mask-generation","identifier":"fig:mask-generation","html_id":"fig-mask-generation","enumerator":"4","children":[{"type":"text","value":"Figure ","key":"oaF4tKXIZk"},{"type":"text","value":"4","key":"Cj4iPEjXV3"},{"type":"text","value":":","key":"Dq8JhI5Gup"}],"template":"Figure %s:","key":"INxe8U0Y37"},{"type":"text","value":"Mask generation workflow substeps.","position":{"start":{"line":91,"column":1},"end":{"line":91,"column":1}},"key":"SleCVoRvKP"}],"key":"JFzJUeJT2X"}],"key":"wLihdrteOV"}],"label":"fig:mask-generation","identifier":"fig:mask-generation","enumerator":"4","html_id":"fig-mask-generation","key":"xBOZryvgqC"},{"type":"heading","depth":4,"position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"children":[{"type":"text","value":"Post-Processing","position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"key":"suNs9aAFW2"}],"identifier":"post-processing","label":"Post-Processing","html_id":"post-processing","implicit":true,"enumerator":"4.2.3","key":"ExO0KX4Hdu"},{"type":"container","kind":"figure","children":[{"type":"image","url":"http://localhost:3100/post-processing-64beff64c6b64b117d7e944816b3c683.png","alt":"Data post-processing workflow substeps.","data":{"altTextIsAutoGenerated":true},"key":"wTlXyJhnTG","urlSource":"post-processing.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":98,"column":1},"end":{"line":98,"column":1}},"children":[{"type":"captionNumber","kind":"figure","label":"fig:post-processing","identifier":"fig:post-processing","html_id":"fig-post-processing","enumerator":"5","children":[{"type":"text","value":"Figure ","key":"b9t0useH7s"},{"type":"text","value":"5","key":"kpDxe8LTPT"},{"type":"text","value":":","key":"gdgM9XXIbS"}],"template":"Figure %s:","key":"VTeiAeuMTs"},{"type":"text","value":"Data post-processing workflow substeps.","position":{"start":{"line":98,"column":1},"end":{"line":98,"column":1}},"key":"r6DhaLZhQZ"}],"key":"NzUm6uv2Qj"}],"key":"RjvfUSjEnY"}],"label":"fig:post-processing","identifier":"fig:post-processing","enumerator":"5","html_id":"fig-post-processing","key":"mwnQjSgLuC"},{"type":"heading","depth":4,"position":{"start":{"line":101,"column":1},"end":{"line":101,"column":1}},"children":[{"type":"text","value":"Accuracy Evaluation","position":{"start":{"line":101,"column":1},"end":{"line":101,"column":1}},"key":"TfZk362oTc"}],"identifier":"accuracy-evaluation","label":"Accuracy Evaluation","html_id":"accuracy-evaluation","implicit":true,"enumerator":"4.2.4","key":"MSei7OCi0c"},{"type":"container","kind":"figure","children":[{"type":"image","url":"http://localhost:3100/accuracy-evaluation-fa62865b14e4cead4d16dc102803fc49.png","alt":"Data post-processing workflow substeps; see Appendix A for methodology details.","data":{"altTextIsAutoGenerated":true},"key":"tXPWTR0G70","urlSource":"accuracy-evaluation.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":105,"column":1},"end":{"line":105,"column":1}},"children":[{"type":"captionNumber","kind":"figure","label":"fig:accuracy-evaluation","identifier":"fig:accuracy-evaluation","html_id":"fig-accuracy-evaluation","enumerator":"6","children":[{"type":"text","value":"Figure ","key":"FmHMENoRQb"},{"type":"text","value":"6","key":"lrH0TfAelo"},{"type":"text","value":":","key":"WLLfduR8vU"}],"template":"Figure %s:","key":"ZqrU6HTDTU"},{"type":"text","value":"Data post-processing workflow substeps; see ","position":{"start":{"line":105,"column":1},"end":{"line":105,"column":1}},"key":"otm6d2lppW"},{"type":"crossReference","position":{"start":{"line":105,"column":1},"end":{"line":105,"column":1}},"children":[{"type":"text","value":"Appendix A","position":{"start":{"line":105,"column":1},"end":{"line":105,"column":1}},"key":"QiYOz1nmcQ"}],"identifier":"accuracy-evaluation-methodology","label":"accuracy-evaluation-methodology","kind":"heading","template":"Section %s","enumerator":"12.1","resolved":true,"html_id":"accuracy-evaluation-methodology","key":"Nkdp98m5ak"},{"type":"text","value":" for methodology details.","position":{"start":{"line":105,"column":1},"end":{"line":105,"column":1}},"key":"ik89oOI7w8"}],"key":"SSzdWJyAdX"}],"key":"J4MJ3aawR6"}],"label":"fig:accuracy-evaluation","identifier":"fig:accuracy-evaluation","enumerator":"6","html_id":"fig-accuracy-evaluation","key":"gEEXAVGE0o"},{"type":"heading","depth":4,"position":{"start":{"line":108,"column":1},"end":{"line":108,"column":1}},"children":[{"type":"text","value":"Benchmarking","position":{"start":{"line":108,"column":1},"end":{"line":108,"column":1}},"key":"xmFOhkJM5e"}],"identifier":"benchmarking","label":"Benchmarking","html_id":"benchmarking","implicit":true,"enumerator":"4.2.5","key":"uwNwHVoznT"},{"type":"container","kind":"figure","children":[{"type":"image","url":"http://localhost:3100/benchmarking-77f425bca54c3b7d70477a20d4a051ba.png","alt":"Benchmarking workflow substeps; see code for methodology details.","data":{"altTextIsAutoGenerated":true},"key":"V3FuSPqbJK","urlSource":"benchmarking.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"children":[{"type":"captionNumber","kind":"figure","label":"fig:benchmarking","identifier":"fig:benchmarking","html_id":"fig-benchmarking","enumerator":"7","children":[{"type":"text","value":"Figure ","key":"e4gT1Q7VnQ"},{"type":"text","value":"7","key":"BSuTVSGgKH"},{"type":"text","value":":","key":"fkzUUMfVyf"}],"template":"Figure %s:","key":"opFj70Ijta"},{"type":"text","value":"Benchmarking workflow substeps; see ","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"key":"jT1WZXYKAH"},{"type":"crossReference","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"children":[{"type":"text","value":"code","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"key":"iWOFz2XGNR"}],"identifier":"code","label":"code","kind":"heading","template":"Section %s","enumerator":"11","resolved":true,"html_id":"code","key":"dJLTh8vE81"},{"type":"text","value":" for methodology details.","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"key":"UjaQcHuhzC"}],"key":"ZI2UfgGTTK"}],"key":"JiwlCwQWsj"}],"label":"fig:benchmarking","identifier":"fig:benchmarking","enumerator":"7","html_id":"fig-benchmarking","key":"EZQtEErccS"},{"type":"heading","depth":2,"position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"children":[{"type":"text","value":"Results","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"key":"DonhbHluhN"}],"identifier":"results","label":"Results","html_id":"results","implicit":true,"enumerator":"5","key":"bY4pr4RfLJ"},{"type":"heading","depth":3,"position":{"start":{"line":117,"column":1},"end":{"line":117,"column":1}},"children":[{"type":"text","value":"Proprietary Workflow","position":{"start":{"line":117,"column":1},"end":{"line":117,"column":1}},"key":"Q9tQjEyRFw"}],"identifier":"proprietary-workflow","label":"Proprietary Workflow","html_id":"proprietary-workflow","implicit":true,"enumerator":"5.1","key":"Jziih3Qoj2"},{"type":"container","kind":"figure","children":[{"type":"image","url":"http://localhost:3100/proprietary-workflow-ee60ae2669b98b1bb550af791cfc12d6.png","alt":"19 false positives (FP) and hundreds of sliver polygons were observed in the output produced using the proprietary software.","data":{"altTextIsAutoGenerated":true},"key":"tbGNoEUJBk","urlSource":"proprietary-workflow-output-evaluation.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"children":[{"type":"captionNumber","kind":"figure","label":"fig:proprietary-workflow-output-evaluation","identifier":"fig:proprietary-workflow-output-evaluation","html_id":"fig-proprietary-workflow-output-evaluation","enumerator":"8","children":[{"type":"text","value":"Figure ","key":"tuZemYSr8C"},{"type":"text","value":"8","key":"GcJ0f2Eo36"},{"type":"text","value":":","key":"wXEqimwdTm"}],"template":"Figure %s:","key":"m4DYecK9jW"},{"type":"text","value":"19 false positives (FP) and hundreds of sliver polygons were observed in the output produced using the proprietary software.","position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"key":"HG4pdjnpgP"}],"key":"RfSyIzP4Lc"}],"key":"Z4duX9YfJq"}],"label":"fig:proprietary-workflow-output-evaluation","identifier":"fig:proprietary-workflow-output-evaluation","enumerator":"8","html_id":"fig-proprietary-workflow-output-evaluation","key":"a2xj4VtLUU"},{"type":"paragraph","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"children":[{"type":"text","value":"The bounding boxes that were output using this workflow (against which we are benchmarking ours) can be viewed as a layer overlain onto the GeoTIFF orthomosaic using GIS software","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"key":"z68OyCTbwu"},{"type":"footnoteReference","identifier":"footnote-4","label":"footnote-4","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"enumerator":"4","key":"Tfzo6FHqvW"},{"type":"text","value":". Certain inferences can be drawn from the output that we won’t go into here; what is of particular use to us is the fact that zero false negatives (FN) were observed in the output, though 19 FP were. This empirical knowledge equips us with something not usually possessed in use cases such as this: the number of true positives (TP), which allows us to leverage such metrics as precision, recall, and the harmonic mean of the two, F1 score, in order to perform a rigorous comparison (see ","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"key":"et0FPamb3M"},{"type":"link","url":"https://colab.research.google.com/drive/1pwnb14s2i7n_VAlfwhBqzDQ0cOb9oGs-?usp=sharing#sandboxMode=true\u0026scrollTo=VNWvzNKU-ePt","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"children":[{"type":"text","value":"code","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"key":"yPR0gD6GbW"}],"urlSource":"https://colab.research.google.com/drive/1pwnb14s2i7n_VAlfwhBqzDQ0cOb9oGs-?usp=sharing#sandboxMode=true\u0026scrollTo=VNWvzNKU-ePt","key":"rmJzZ6Ng6p"},{"type":"text","value":").","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"key":"XG0MGDoKCB"}],"key":"ZN2EsbYBME"},{"type":"heading","depth":3,"position":{"start":{"line":128,"column":1},"end":{"line":128,"column":1}},"children":[{"type":"text","value":"Open Source Workflow","position":{"start":{"line":128,"column":1},"end":{"line":128,"column":1}},"key":"JACBdwwn2j"}],"identifier":"open-source-workflow","label":"Open Source Workflow","html_id":"open-source-workflow","implicit":true,"enumerator":"5.2","key":"HyYVlOCsLo"},{"type":"container","kind":"figure","children":[{"type":"image","url":"http://localhost:3100/open-source-false-po-193be7a399470bc17c88d351fd64c91d.png","alt":"18 FP were observed in the output produced using the open source workflow.","data":{"altTextIsAutoGenerated":true},"key":"aLczXl8Tgs","urlSource":"open-source-false-positive-collage.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"children":[{"type":"captionNumber","kind":"figure","label":"fig:open-source-workflow-output-evaluation","identifier":"fig:open-source-workflow-output-evaluation","html_id":"fig-open-source-workflow-output-evaluation","enumerator":"9","children":[{"type":"text","value":"Figure ","key":"BDgrfST7hV"},{"type":"text","value":"9","key":"BEaTlfQX5J"},{"type":"text","value":":","key":"d142Gk2Vg6"}],"template":"Figure %s:","key":"TcQwwQY4eT"},{"type":"text","value":"18 FP were observed in the output produced using the open source workflow.","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"key":"e4SMhR6pFT"}],"key":"p9epbLzPoY"}],"key":"edYKHRqnal"}],"label":"fig:open-source-workflow-output-evaluation","identifier":"fig:open-source-workflow-output-evaluation","enumerator":"9","html_id":"fig-open-source-workflow-output-evaluation","key":"EEdv1dcDAZ"},{"type":"paragraph","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"children":[{"type":"text","value":"Knowing how many TP (18,736) there are in the benchmark output ultimately allows us to derive how many FP (18) and FN (65) there are in our workflow output and conduct our performance comparison.","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"ltePeNXiWo"}],"key":"Ao0sNMN0FN"},{"type":"container","kind":"table","children":[{"type":"caption","children":[{"type":"paragraph","children":[{"type":"captionNumber","kind":"table","label":"tbl:performance-comparison","identifier":"tbl:performance-comparison","html_id":"tbl-performance-comparison","enumerator":"1","children":[{"type":"text","value":"Table ","key":"NUTLWpAJtb"},{"type":"text","value":"1","key":"TwKKZEAOzz"},{"type":"text","value":":","key":"gUPZDqhTWi"}],"template":"Table %s:","key":"PBCNJcRdhw"},{"type":"text","value":"Performance Comparison","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"wXbCIk3quO"}],"key":"kbwQRz2fw0"}],"key":"akmvzvSE2B"},{"type":"table","children":[{"type":"tableRow","children":[{"type":"tableCell","header":true,"align":"center","rowspan":2,"children":[{"type":"text","value":"Workflow","key":"OcEkiQYKrN"}],"key":"SMhRIFx1vD"},{"type":"tableCell","header":true,"align":"center","colspan":3,"children":[{"type":"text","value":"Detection Quality Metrics","key":"AO5hGLQEWn"}],"key":"lamM2pn7CP"},{"type":"tableCell","header":true,"align":"center","colspan":2,"children":[{"type":"text","value":"Localization Accuracy Metrics","key":"dpoEtwN3Td"}],"key":"VafyeOMEw3"}],"key":"ruTCoDaciX"},{"type":"tableRow","children":[{"type":"tableCell","header":true,"align":"center","children":[{"type":"text","value":"Precision","key":"vf7IgQMTBX"}],"key":"RH2tGnEpcr"},{"type":"tableCell","header":true,"align":"center","children":[{"type":"text","value":"Recall","key":"A791cgAYpU"}],"key":"Bt3JkZeb76"},{"type":"tableCell","header":true,"align":"center","children":[{"type":"text","value":"F1 Score","key":"kfHdYrssZ8"}],"key":"TOlrGTOslZ"},{"type":"tableCell","header":true,"align":"center","children":[{"type":"text","value":"Mean Deviation (cm)","key":"Yqwpip1LDM"}],"key":"OS1Yr3pzYn"},{"type":"tableCell","header":true,"align":"center","children":[{"type":"text","value":"IoU","key":"smXSvRdkmG"}],"key":"RQsLBk03Fa"}],"key":"RK33N1ULjY"},{"type":"tableRow","children":[{"type":"tableCell","align":"center","children":[{"type":"strong","children":[{"type":"emphasis","children":[{"type":"text","value":"Proprietary","key":"ss5v7qpQpV"}],"key":"kLDGpk3CvP"}],"key":"iiDrRpdE9v"}],"key":"Rucb9RJk3h"},{"type":"tableCell","align":"center","children":[{"type":"text","value":"0.9990","key":"dz0LqmmIkY"}],"key":"qb0MKONxY7"},{"type":"tableCell","align":"center","children":[{"type":"text","value":"1.0000","key":"maWA7uHisO"}],"key":"Oi2mrAa6ii"},{"type":"tableCell","align":"center","children":[{"type":"text","value":"0.9995","key":"WnQQDwaa9r"}],"key":"b2MJhFvteU"},{"type":"tableCell","align":"center","children":[{"type":"text","value":"1.39","key":"JeWk5l011p"}],"key":"zRftVw0iR8"},{"type":"tableCell","align":"center","children":[{"type":"text","value":"0.18","key":"uZNlXsMHQb"}],"key":"ajmXvmlGfx"}],"key":"TyaXg5AQLt"},{"type":"tableRow","children":[{"type":"tableCell","align":"center","children":[{"type":"strong","children":[{"type":"emphasis","children":[{"type":"text","value":"Open Source","key":"NBiynP3Qgk"}],"key":"iUblmXbmnE"}],"key":"ddXdSxRcCJ"}],"key":"Ge0sIhyZCH"},{"type":"tableCell","align":"center","children":[{"type":"text","value":"0.9990","key":"MC8aWL6wDx"}],"key":"APdx3FxgqE"},{"type":"tableCell","align":"center","children":[{"type":"text","value":"0.9956","key":"YwWIM9sysu"}],"key":"pDCDhZU1Pj"},{"type":"tableCell","align":"center","children":[{"type":"text","value":"0.9973","key":"T6wSAQHUGi"}],"key":"lQIU0fbZhw"},{"type":"tableCell","align":"center","children":[{"type":"text","value":"1.20","key":"zcl26zTdjX"}],"key":"B1QWOSxMXK"},{"type":"tableCell","align":"center","children":[{"type":"text","value":"0.74","key":"W1qmBwAChi"}],"key":"sJND1bbmwn"}],"key":"vgM5DizPh7"}],"key":"sazweYzrFU"}],"label":"tbl:performance-comparison","identifier":"tbl:performance-comparison","enumerator":"1","html_id":"tbl-performance-comparison","key":"jJd6EhVGLk"},{"type":"paragraph","position":{"start":{"line":172,"column":1},"end":{"line":172,"column":1}},"children":[{"type":"text","value":"Having output geometry with real-world coordinates and QC geometry created based on the empirical observation that empty plant pots tend to be ~64 pixels wide and tall; QC points corresponding to actual pot centroids allowed us to create 64-by-64px boxes to facilitate our IoU calculations (see ","position":{"start":{"line":172,"column":1},"end":{"line":172,"column":1}},"key":"Gwq33bV4Zk"},{"type":"link","url":"https://colab.research.google.com/drive/1NqDTYw0V9yRnZtoT6Pc7ZJ3ATe7CTue8?usp=sharing#sandboxMode=true","position":{"start":{"line":172,"column":1},"end":{"line":172,"column":1}},"children":[{"type":"text","value":"code","position":{"start":{"line":172,"column":1},"end":{"line":172,"column":1}},"key":"WRK2dqzLlH"}],"urlSource":"https://colab.research.google.com/drive/1NqDTYw0V9yRnZtoT6Pc7ZJ3ATe7CTue8?usp=sharing#sandboxMode=true","key":"yueKNmYzVc"},{"type":"text","value":"). These calculations further allow us to assess the relative alignment between the detection output geometry and our “ground truth” geometry.","position":{"start":{"line":172,"column":1},"end":{"line":172,"column":1}},"key":"s5OSgoIQcA"}],"key":"ZGuUpDblxs"},{"type":"paragraph","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"children":[{"type":"text","value":"This work makes it easy to identify down to the individual QC point ID level which detection centroids deviate from said point by more than 3 cm, which is the tolerance specified by our client. In aggregate, we are able to gain a quantified sense of the mean deviation (in cm) of the output produced by each workflow. However, visual inspection reveals that some QC points flagged as having cooresponding detection centroids that are out-of-tolerance were, in fact, themselves off-center. This is to say the some detections from both the open source workflow and the benchmark workflow were flagged as being out-of-tolerance when they observably were not.","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"key":"TXDIpr5Ghd"}],"key":"ZYSv0BVoLU"},{"type":"container","kind":"figure","children":[{"type":"image","url":"http://localhost:3100/qc-point-91-collage-6e38bc8ea993f3396b106ab126ca5f7e.png","alt":"Visual inspection of the detected centroids relative to QC point 91 reveal that the QC point is off-center.","data":{"altTextIsAutoGenerated":true},"key":"rYj62fNqHA","urlSource":"qc-point-91-collage.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":178,"column":1},"end":{"line":178,"column":1}},"children":[{"type":"captionNumber","kind":"figure","label":"fig:qc-point-91","identifier":"fig:qc-point-91","html_id":"fig-qc-point-91","enumerator":"10","children":[{"type":"text","value":"Figure ","key":"WukNqHOvnG"},{"type":"text","value":"10","key":"gcjveSkxkw"},{"type":"text","value":":","key":"N8tlhm1kis"}],"template":"Figure %s:","key":"SegC4AfHpy"},{"type":"text","value":"Visual inspection of the detected centroids relative to QC point 91 reveal that the QC point is off-center.","position":{"start":{"line":178,"column":1},"end":{"line":178,"column":1}},"key":"uWhWJR6LMF"}],"key":"bvM4394f2e"}],"key":"g43lx7F3HW"}],"label":"fig:qc-point-91","identifier":"fig:qc-point-91","enumerator":"10","html_id":"fig-qc-point-91","key":"QZr6TAa8ua"},{"type":"paragraph","position":{"start":{"line":181,"column":1},"end":{"line":181,"column":1}},"children":[{"type":"text","value":"Visual inspection also reveals that our detections (in pink) and those produced using the commercial software (in beige) have greater overall coverage with respect to the QC geometry (in grey). This provides intuition as to why the IoU calculations revealed a 400% increase in coverage with respect to the geometry produced using SAM’s automatic mask generator, zero-shot.","position":{"start":{"line":181,"column":1},"end":{"line":181,"column":1}},"key":"vy3i99y4bg"}],"key":"xGRZKBxxPG"},{"type":"heading","depth":2,"position":{"start":{"line":183,"column":1},"end":{"line":183,"column":1}},"children":[{"type":"text","value":"Discussion","position":{"start":{"line":183,"column":1},"end":{"line":183,"column":1}},"key":"JMkGao8DDq"}],"identifier":"discussion","label":"Discussion","html_id":"discussion","implicit":true,"enumerator":"6","key":"qGZUY6RpQl"},{"type":"heading","depth":2,"position":{"start":{"line":187,"column":1},"end":{"line":187,"column":1}},"children":[{"type":"text","value":"Conclusion","position":{"start":{"line":187,"column":1},"end":{"line":187,"column":1}},"key":"uOWB7d3NdA"}],"identifier":"conclusion","label":"Conclusion","html_id":"conclusion","implicit":true,"enumerator":"7","key":"HADGQzhYIJ"},{"type":"paragraph","position":{"start":{"line":189,"column":1},"end":{"line":189,"column":1}},"children":[{"type":"text","value":"We present a robust, open source workflow for object detection and spatial localization in high-resolution drone orthomosaics, leveraging SAM’s zero-shot segmentation capabilities. Our quantitative evaluation demonstrates improved accuracy over a commercially available software solution, underscoring the potential of foundation models and open source tools to advance scalable, cost-effective feature extraction in agriculture. This work provides a template for further research and deployment in diverse contexts.","position":{"start":{"line":189,"column":1},"end":{"line":189,"column":1}},"key":"wHIz09Crvq"}],"key":"ERLP2I5bmT"},{"type":"paragraph","position":{"start":{"line":191,"column":1},"end":{"line":191,"column":1}},"children":[{"type":"text","value":"To our knowledge, this is the first comparative evaluation of an open source segmentation model (SAM) against commercial software in a context requiring high (\u003c 3 cm) spatial accuracy. Our results demonstrate that the workflow not only matches but in some cases exceeds performance metrics with respect to the evaluated output.","position":{"start":{"line":191,"column":1},"end":{"line":191,"column":1}},"key":"YC6UR8I1Ru"}],"key":"qZXTEOvhUK"},{"type":"heading","depth":2,"position":{"start":{"line":193,"column":1},"end":{"line":193,"column":1}},"children":[{"type":"text","value":"Acknowledgments","position":{"start":{"line":193,"column":1},"end":{"line":193,"column":1}},"key":"NG5DitT3mt"}],"identifier":"acknowledgments","label":"Acknowledgments","html_id":"acknowledgments","implicit":true,"enumerator":"8","key":"mDY90o1ZBs"},{"type":"paragraph","position":{"start":{"line":195,"column":1},"end":{"line":195,"column":1}},"children":[{"type":"text","value":"We gratefully acknowledge the contributions of the open source community — thank you to the giants on whose shoulders we stand.","position":{"start":{"line":195,"column":1},"end":{"line":195,"column":1}},"key":"b8vIFPOPvb"}],"key":"RsiCHmmWDv"},{"type":"paragraph","position":{"start":{"line":197,"column":1},"end":{"line":197,"column":1}},"children":[{"type":"text","value":"This work was funded by FiOR Innovations and Woodburn Nursery \u0026 Azaleas. We deeply appreciate their support and partnership.","position":{"start":{"line":197,"column":1},"end":{"line":197,"column":1}},"key":"jkmcMxbh1d"}],"key":"Z59Uv8NRh3"},{"type":"paragraph","position":{"start":{"line":199,"column":1},"end":{"line":199,"column":1}},"children":[{"type":"text","value":"Special thanks to Paniz Herrera, MBA, MSIST, for her invaluable suggestions.","position":{"start":{"line":199,"column":1},"end":{"line":199,"column":1}},"key":"NlffW8ITTl"}],"key":"GSpARDmsRH"},{"type":"paragraph","position":{"start":{"line":201,"column":1},"end":{"line":201,"column":1}},"children":[{"type":"text","value":"We also thank Ryan Marinelli, PhD Fellow at the University of Oslo, for his assistance with proofreading and his insightful feedback.","position":{"start":{"line":201,"column":1},"end":{"line":201,"column":1}},"key":"wigRyhJT12"}],"key":"nx0mwHQlCw"},{"type":"paragraph","position":{"start":{"line":203,"column":1},"end":{"line":203,"column":1}},"children":[{"type":"text","value":"Finally, to Danny Clifford, your insightful questions and targeted suggestions for improvement continue to be of tremendous value. Thank you.","position":{"start":{"line":203,"column":1},"end":{"line":203,"column":1}},"key":"XFcDjDar3v"}],"key":"WsfoAY9uw3"},{"type":"heading","depth":2,"position":{"start":{"line":205,"column":1},"end":{"line":205,"column":1}},"children":[{"type":"text","value":"Conflicts of Interest","position":{"start":{"line":205,"column":1},"end":{"line":205,"column":1}},"key":"wvlzvn9XZh"}],"identifier":"conflicts-of-interest","label":"Conflicts of Interest","html_id":"conflicts-of-interest","implicit":true,"enumerator":"9","key":"ZLDeDm2QHZ"},{"type":"paragraph","position":{"start":{"line":207,"column":1},"end":{"line":207,"column":1}},"children":[{"type":"text","value":"The author declares no conflicts of interest.","position":{"start":{"line":207,"column":1},"end":{"line":207,"column":1}},"key":"tfye7PezJx"}],"key":"nwqjWPXT71"},{"type":"heading","depth":2,"position":{"start":{"line":209,"column":1},"end":{"line":209,"column":1}},"children":[{"type":"text","value":"AI Usage Disclosure","position":{"start":{"line":209,"column":1},"end":{"line":209,"column":1}},"key":"MPt9B4zdsQ"}],"identifier":"ai-usage-disclosure","label":"AI Usage Disclosure","html_id":"ai-usage-disclosure","implicit":true,"enumerator":"10","key":"cKkaI6wZFy"},{"type":"paragraph","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"children":[{"type":"text","value":"AI tools (ChatGPT, Perplexity, and NotebookLM) were used:","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"fmVGyZyZ9E"}],"key":"hQvmSVoSLI"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":213,"column":1},"end":{"line":216,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":213,"column":1},"end":{"line":213,"column":1}},"children":[{"type":"text","value":"in writing portions of the workflow integration code,","position":{"start":{"line":213,"column":1},"end":{"line":213,"column":1}},"key":"ojkONRNJaA"}],"key":"WKyyf6Y9Cu"},{"type":"listItem","spread":true,"position":{"start":{"line":214,"column":1},"end":{"line":214,"column":1}},"children":[{"type":"text","value":"to generate Matplotlib subplots, process flow diagrams, ","position":{"start":{"line":214,"column":1},"end":{"line":214,"column":1}},"key":"d4irHIemFH"},{"type":"span","style":{"fontFamily":"serif"},"children":[{"type":"text","value":"L ","key":"uzeNekT73B"},{"type":"span","style":{"verticalAlign":"0.4ex","fontSize":"0.8em"},"children":[{"type":"text","value":"A","key":"AjftDeMvN1"}],"key":"DzioGWVvdd"},{"type":"text","value":" T ","key":"HDoO2C4tVe"},{"type":"span","style":{"verticalAlign":"-0.3ex","fontSize":"0.8em"},"children":[{"type":"text","value":"E","key":"A5ChCHbDRJ"}],"key":"p7ORsivoQf"},{"type":"text","value":" X","key":"sCkrHzmBvT"}],"key":"kqCGX2w5SU"},{"type":"text","value":", etc.","position":{"start":{"line":214,"column":1},"end":{"line":214,"column":1}},"key":"WSlxeDK6Or"}],"key":"d42yXapbaA"},{"type":"listItem","spread":true,"position":{"start":{"line":215,"column":1},"end":{"line":216,"column":1}},"children":[{"type":"text","value":"for proofreading and light revision to reduce potential publication errors.","position":{"start":{"line":215,"column":1},"end":{"line":215,"column":1}},"key":"xrvNGspsqX"}],"key":"U4YCaa5Yjb"}],"key":"hKJRz4cj87"},{"type":"heading","depth":2,"position":{"start":{"line":217,"column":1},"end":{"line":217,"column":1}},"children":[{"type":"text","value":"Code","position":{"start":{"line":217,"column":1},"end":{"line":217,"column":1}},"key":"A2tWqxlWUB"}],"identifier":"code","label":"Code","html_id":"code","implicit":true,"enumerator":"11","key":"QrWzAN1ROX"},{"type":"paragraph","position":{"start":{"line":219,"column":1},"end":{"line":222,"column":1}},"children":[{"type":"link","url":"https://github.com/nickmccarty/scipy-2025","position":{"start":{"line":219,"column":1},"end":{"line":219,"column":1}},"children":[{"type":"image","url":"http://localhost:3100/ec1d732ee9507693b3cf59f83e0e3fe8.svg","alt":"GitHub","position":{"start":{"line":219,"column":1},"end":{"line":219,"column":1}},"key":"kQgOAhDLjA","urlSource":"https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge\u0026logo=github\u0026logoColor=white"}],"urlSource":"https://github.com/nickmccarty/scipy-2025","error":true,"key":"bey0dtLkCA"},{"type":"text","value":"\n","position":{"start":{"line":219,"column":1},"end":{"line":219,"column":1}},"key":"u1cUppQGvf"},{"type":"link","url":"https://colab.research.google.com/drive/1pwnb14s2i7n_VAlfwhBqzDQ0cOb9oGs-?usp=sharing#sandboxMode=true","children":[{"type":"image","url":"http://localhost:3100/7e2db436150c38a00650f96925aa5581.svg","alt":"Open In Colab","key":"vDGPxcv4OX","urlSource":"https://colab.research.google.com/assets/colab-badge.svg"}],"urlSource":"https://colab.research.google.com/drive/1pwnb14s2i7n_VAlfwhBqzDQ0cOb9oGs-?usp=sharing#sandboxMode=true","key":"roSMRglLvY"}],"key":"ESnaw96wre"},{"type":"heading","depth":2,"position":{"start":{"line":224,"column":1},"end":{"line":224,"column":1}},"children":[{"type":"text","value":"Appendix A","position":{"start":{"line":224,"column":1},"end":{"line":224,"column":1}},"key":"vtyMtqmsqj"}],"identifier":"appendix-a","label":"Appendix A","html_id":"appendix-a","implicit":true,"enumerator":"12","key":"NhcGOq4TV3"},{"type":"heading","depth":3,"position":{"start":{"line":226,"column":1},"end":{"line":226,"column":1}},"children":[{"type":"text","value":"Accuracy Evaluation Methodology","position":{"start":{"line":226,"column":1},"end":{"line":226,"column":1}},"key":"bnFkqaXVVk"}],"identifier":"accuracy-evaluation-methodology","label":"Accuracy Evaluation Methodology","html_id":"accuracy-evaluation-methodology","implicit":true,"enumerator":"12.1","key":"Z0m4ne4iGz"},{"type":"paragraph","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"children":[{"type":"text","value":"The evaluation focuses on two primary categories of metrics: ","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"key":"R3k38WSY7T"},{"type":"emphasis","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"children":[{"type":"strong","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"children":[{"type":"text","value":"localization accuracy","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"key":"fshMxTXoaS"}],"key":"L8mSCKxwUC"}],"key":"SONPU4Czbm"},{"type":"text","value":" and ","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"key":"BuEodW8b4B"},{"type":"emphasis","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"children":[{"type":"strong","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"children":[{"type":"text","value":"detection quality","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"key":"oPEAOQ5VTi"}],"key":"Q6UKvW2yaB"}],"key":"XgTfRLJzgT"},{"type":"text","value":"; the employed methodology relies on the following data:","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"key":"bvEZF6NSLw"}],"key":"ylFhLKWYou"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":230,"column":1},"end":{"line":233,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":230,"column":1},"end":{"line":230,"column":1}},"children":[{"type":"strong","position":{"start":{"line":230,"column":1},"end":{"line":230,"column":1}},"children":[{"type":"text","value":"Ground Truth Quality Control (QC) Points","position":{"start":{"line":230,"column":1},"end":{"line":230,"column":1}},"key":"Q4321eXDA3"}],"key":"ghKZSWVR7V"},{"type":"text","value":" (","position":{"start":{"line":230,"column":1},"end":{"line":230,"column":1}},"key":"hCcuUtdsc1"},{"type":"inlineMath","value":"P_{QC}","position":{"start":{"line":230,"column":1},"end":{"line":230,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eP\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eP_{QC}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.13889em;\"\u003eP\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\"\u003eQC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"SCGw0KUyjI"},{"type":"text","value":"), defined as a set of ","position":{"start":{"line":230,"column":1},"end":{"line":230,"column":1}},"key":"PzLdwRN8Nr"},{"type":"inlineMath","value":"N_{QC}","position":{"start":{"line":230,"column":1},"end":{"line":230,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN_{QC}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.109em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\"\u003eQC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"oSBiPv1eeQ"},{"type":"text","value":" known spatial coordinates, ","position":{"start":{"line":230,"column":1},"end":{"line":230,"column":1}},"key":"Si3ay3eRMI"},{"type":"inlineMath","value":"P_{QC} = \\{p_j\\}_{j=1}^{N_{QC}}","position":{"start":{"line":230,"column":1},"end":{"line":230,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eP\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e{\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ep\u003c/mi\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/msub\u003e\u003cmsubsup\u003e\u003cmo stretchy=\"false\"\u003e}\u003c/mo\u003e\u003cmrow\u003e\u003cmi\u003ej\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003cmsub\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/msubsup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eP_{QC} = \\{p_j\\}_{j=1}^{N_{QC}}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.13889em;\"\u003eP\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\"\u003eQC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.4336em;vertical-align:-0.413em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e{\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ep\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e\u003cspan class=\"mclose\"\u003e}\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.0207em;\"\u003e\u003cspan style=\"top:-2.4231em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003cspan class=\"mrel mtight\"\u003e=\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.2423em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3448em;\"\u003e\u003cspan style=\"top:-2.3567em;margin-left:-0.109em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\"\u003eQC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2822em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.413em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"qZvLsh0fcr"},{"type":"text","value":", where each ","position":{"start":{"line":230,"column":1},"end":{"line":230,"column":1}},"key":"lk3uxlEHCm"},{"type":"inlineMath","value":"p_j = (x_j, y_j)","position":{"start":{"line":230,"column":1},"end":{"line":230,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ep\u003c/mi\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ey\u003c/mi\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ep_j = (x_j, y_j)\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7167em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ep\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ey\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"HICjPlHwgB"},{"type":"text","value":" represents the centroid (in real-world coordinates) of our object of interest (empty plant pots), serving as the ground truth for spatial localization.","position":{"start":{"line":230,"column":1},"end":{"line":230,"column":1}},"key":"GzLhWR8A0V"}],"key":"gU61hK5mA9"},{"type":"listItem","spread":true,"position":{"start":{"line":231,"column":1},"end":{"line":231,"column":1}},"children":[{"type":"strong","position":{"start":{"line":231,"column":1},"end":{"line":231,"column":1}},"children":[{"type":"text","value":"Detected Object Centroids","position":{"start":{"line":231,"column":1},"end":{"line":231,"column":1}},"key":"OKrnO6JeVV"}],"key":"gdBUqhXTQt"},{"type":"text","value":" (","position":{"start":{"line":231,"column":1},"end":{"line":231,"column":1}},"key":"Ad5rmlnGxx"},{"type":"inlineMath","value":"C_{Det}","position":{"start":{"line":231,"column":1},"end":{"line":231,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eC_{Det}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eDe\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"cs1rlePrgA"},{"type":"text","value":") are used, which are a set of ","position":{"start":{"line":231,"column":1},"end":{"line":231,"column":1}},"key":"VNSFzFvg9M"},{"type":"inlineMath","value":"N_{Det}","position":{"start":{"line":231,"column":1},"end":{"line":231,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN_{Det}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.109em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eDe\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"X7DEHzFeUI"},{"type":"text","value":" centroids, ","position":{"start":{"line":231,"column":1},"end":{"line":231,"column":1}},"key":"NktycHlsMM"},{"type":"inlineMath","value":"C_{Det} = \\{c_k\\}_{k=1}^{N_{Det}}","position":{"start":{"line":231,"column":1},"end":{"line":231,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e{\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ec\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003cmsubsup\u003e\u003cmo stretchy=\"false\"\u003e}\u003c/mo\u003e\u003cmrow\u003e\u003cmi\u003ek\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003cmsub\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/msubsup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eC_{Det} = \\{c_k\\}_{k=1}^{N_{Det}}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eDe\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.2247em;vertical-align:-0.3013em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e{\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ec\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e\u003cspan class=\"mclose\"\u003e}\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.9234em;\"\u003e\u003cspan style=\"top:-2.3987em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003cspan class=\"mrel mtight\"\u003e=\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.1451em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3448em;\"\u003e\u003cspan style=\"top:-2.3567em;margin-left:-0.109em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eDe\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1433em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3013em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"KAmfwKCu4Z"},{"type":"text","value":", where each ","position":{"start":{"line":231,"column":1},"end":{"line":231,"column":1}},"key":"If46guowzE"},{"type":"inlineMath","value":"c_k = (x'_k, y'_k)","position":{"start":{"line":231,"column":1},"end":{"line":231,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ec\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsubsup\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003cmo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\"\u003e′\u003c/mo\u003e\u003c/msubsup\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsubsup\u003e\u003cmi\u003ey\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003cmo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\"\u003e′\u003c/mo\u003e\u003c/msubsup\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ec_k = (x\u0026#x27;_k, y\u0026#x27;_k)\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ec\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.035em;vertical-align:-0.2831em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.7519em;\"\u003e\u003cspan style=\"top:-2.4169em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e′\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2831em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ey\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.7519em;\"\u003e\u003cspan style=\"top:-2.4169em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e′\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2831em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"DNfhUVhWgI"},{"type":"text","value":" is the centroid extracted from a polygon representing an object detected by the workflow.","position":{"start":{"line":231,"column":1},"end":{"line":231,"column":1}},"key":"SJq58LRMbZ"}],"key":"pDwcTq4xDu"},{"type":"listItem","spread":true,"position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"children":[{"type":"strong","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"children":[{"type":"text","value":"Detected Object Polygons","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"key":"QYghwWl7vJ"}],"key":"nEn1FwcGGD"},{"type":"text","value":" (","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"key":"ryWXWqrjty"},{"type":"inlineMath","value":"G_{Det}","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eG\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eG_{Det}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eG\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eDe\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"vZxGv493wy"},{"type":"text","value":") are included, representing a set of ","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"key":"PbQMG3JQmM"},{"type":"inlineMath","value":"N_{Det}","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN_{Det}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.109em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eDe\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"gKAum6opzj"},{"type":"text","value":" polygons, ","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"key":"rf93RFUZeg"},{"type":"inlineMath","value":"G_{Det} = \\{g_k\\}_{k=1}^{N_{Det}},","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eG\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e{\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003eg\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003cmsubsup\u003e\u003cmo stretchy=\"false\"\u003e}\u003c/mo\u003e\u003cmrow\u003e\u003cmi\u003ek\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003cmsub\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/msubsup\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eG_{Det} = \\{g_k\\}_{k=1}^{N_{Det}},\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eG\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eDe\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.2247em;vertical-align:-0.3013em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e{\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eg\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e\u003cspan class=\"mclose\"\u003e}\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.9234em;\"\u003e\u003cspan style=\"top:-2.3987em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003cspan class=\"mrel mtight\"\u003e=\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.1451em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3448em;\"\u003e\u003cspan style=\"top:-2.3567em;margin-left:-0.109em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eDe\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1433em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3013em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"rMX5mRMHEC"},{"type":"text","value":" where each ","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"key":"dNZ6wHmTwn"},{"type":"inlineMath","value":"g_k","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eg\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eg_k\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eg\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"nY0luqptit"},{"type":"text","value":" is a polygon generated from a SAM-produced mask after post-processing.","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"key":"lFg6LklZBp"}],"key":"fExxcHl5ii"},{"type":"listItem","spread":true,"position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"children":[{"type":"strong","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"children":[{"type":"text","value":"Ground Truth Polygons","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"key":"uaYAg9pyhn"}],"key":"vsbGRFWwlr"},{"type":"text","value":" (","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"key":"hAEZsxYRqM"},{"type":"inlineMath","value":"G_{GT}","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eG\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eG\u003c/mi\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eG_{GT}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eG\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eGT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"bRB4TWlGIx"},{"type":"text","value":") the calculation of Intersection over Union (IoU) implies the existence of a corresponding set of ","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"key":"s3kWItykR2"},{"type":"inlineMath","value":"N_{QC}","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN_{QC}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.109em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\"\u003eQC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"L33PGBUQPX"},{"type":"text","value":" ground truth polygons, ","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"key":"FnFaSCorGQ"},{"type":"inlineMath","value":"G_{GT} = \\{g'_j\\}_{j=1}^{N_{QC}}","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eG\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eG\u003c/mi\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e{\u003c/mo\u003e\u003cmsubsup\u003e\u003cmi\u003eg\u003c/mi\u003e\u003cmi\u003ej\u003c/mi\u003e\u003cmo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\"\u003e′\u003c/mo\u003e\u003c/msubsup\u003e\u003cmsubsup\u003e\u003cmo stretchy=\"false\"\u003e}\u003c/mo\u003e\u003cmrow\u003e\u003cmi\u003ej\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003cmsub\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/msubsup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eG_{GT} = \\{g\u0026#x27;_j\\}_{j=1}^{N_{QC}}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eG\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3283em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eGT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.4336em;vertical-align:-0.413em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e{\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eg\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.7519em;\"\u003e\u003cspan style=\"top:-2.4413em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e′\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3948em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e\u003cspan class=\"mclose\"\u003e}\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.0207em;\"\u003e\u003cspan style=\"top:-2.4231em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003cspan class=\"mrel mtight\"\u003e=\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.2423em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3448em;\"\u003e\u003cspan style=\"top:-2.3567em;margin-left:-0.109em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\"\u003eQC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2822em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.413em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"MfRDVeP76j"},{"type":"text","value":", where each ","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"key":"CLbSwOeUCx"},{"type":"inlineMath","value":"g'_j","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsubsup\u003e\u003cmi\u003eg\u003c/mi\u003e\u003cmi\u003ej\u003c/mi\u003e\u003cmo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\"\u003e′\u003c/mo\u003e\u003c/msubsup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eg\u0026#x27;_j\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.1467em;vertical-align:-0.3948em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eg\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.7519em;\"\u003e\u003cspan style=\"top:-2.4413em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e′\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3948em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"ZavN4NOZWf"},{"type":"text","value":" delineates the extent of the object associated with ground truth point ","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"key":"YGqpZhAO3K"},{"type":"inlineMath","value":"p_j","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ep\u003c/mi\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ep_j\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7167em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ep\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"yU5f0vwklN"},{"type":"text","value":". This allows for the quantification of the spatial alignment between the detection bounding boxes and those associated with the QC points, in aggregate. The provided ","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"key":"xJt1tPMHG3"},{"type":"crossReference","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"children":[{"type":"text","value":"code","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"key":"lbChwaw46v"}],"identifier":"code","label":"code","kind":"heading","template":"Section %s","enumerator":"11","resolved":true,"html_id":"code","key":"QJZfs0DnWW"},{"type":"text","value":" details how we created this geometry and performed the calculations.","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"key":"CeJPBAsYtU"}],"key":"oksksSd1JH"}],"key":"w3kLXXocXQ"},{"type":"footnoteDefinition","identifier":"footnote-1","label":"footnote-1","position":{"start":{"line":233,"column":1},"end":{"line":233,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Output evaluation details are discussed in ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"Yw5nCl34gW"},{"type":"crossReference","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Appendix A","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"JNiSVjS6MD"}],"identifier":"accuracy-evaluation-methodology","label":"accuracy-evaluation-methodology","kind":"heading","template":"Section %s","enumerator":"12.1","resolved":true,"html_id":"accuracy-evaluation-methodology","key":"apXpqwBJDR"},{"type":"text","value":".","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"VaLkTa1KZx"}],"key":"J0htDld4Fq"}],"enumerator":"1","key":"s0i42YVz5m"},{"type":"footnoteDefinition","identifier":"footnote-2","label":"footnote-2","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"children":[{"type":"text","value":"See ","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"YiV2PaC3AK"},{"type":"link","url":"https://raw.githubusercontent.com/nickmccarty/scipy-2025/refs/heads/main/requirements.txt","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"children":[{"type":"text","value":"requirements.txt","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"PEN5ofvpIc"}],"urlSource":"https://raw.githubusercontent.com/nickmccarty/scipy-2025/refs/heads/main/requirements.txt","key":"vm8dsun1zF"},{"type":"text","value":" for version details.","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"QMz0TMZgyw"}],"key":"Bm08cQlsnX"}],"enumerator":"2","key":"rGE94XwC00"},{"type":"footnoteDefinition","identifier":"footnote-3","label":"footnote-3","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"children":[{"type":"text","value":"Inference was accelerated using ","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"oubv3VbsV4"},{"type":"inlineCode","value":"CUDA 12","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"dTFKB3iWNP"},{"type":"text","value":" (","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"waVoF4JZNF"},{"type":"inlineCode","value":"cuDF 25.2.1","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"d9Xq3FeIA5"},{"type":"text","value":") on a ","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"DM4sX4wFUS"},{"type":"inlineCode","value":"T4","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"o8xLMskCmo"},{"type":"text","value":" GPU within our Colab notebook environment.","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"L9SVUBqPOU"}],"key":"gazA379rLF"}],"enumerator":"3","key":"c8borr4M2b"},{"type":"footnoteDefinition","identifier":"footnote-4","label":"footnote-4","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":126,"column":1},"end":{"line":126,"column":1}},"children":[{"type":"text","value":"We use open source QGIS ","position":{"start":{"line":126,"column":1},"end":{"line":126,"column":1}},"key":"fLKnmaC98s"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":126,"column":1},"end":{"line":126,"column":1}},"children":[{"type":"cite","identifier":"qgis","label":"qgis","kind":"parenthetical","position":{"start":{"line":126,"column":26},"end":{"line":126,"column":31}},"children":[{"type":"text","value":"QGIS Development Team, 2021","key":"JYSfua3Dpf"}],"enumerator":"17","key":"f8XAMunngR"}],"key":"LReSXhd0qN"},{"type":"text","value":" as our selected data viewer.","position":{"start":{"line":126,"column":1},"end":{"line":126,"column":1}},"key":"DCLD66mwRP"}],"key":"ZYoft53Vll"}],"enumerator":"4","key":"v38yiigzxE"}],"key":"InSPpdCVGs"}],"key":"ilCfciTjQ7"},"references":{"cite":{"order":["wu23","osco23","mayladan23","kirillov23","gdal","shapely","geopandas","rasterio","matplotlib","numpy","opencv","openpyxl","pandas1","pandas2","pillow","pytorch","qgis"],"data":{"wu23":{"label":"wu23","enumerator":"1","doi":"10.21105/joss.05663","html":"Wu, Q., \u0026 Osco, L. P. (2023). samgeo: A Python package for segmenting geospatial data with the Segment Anything Model (SAM). \u003ci\u003eJournal of Open Source Software\u003c/i\u003e, \u003ci\u003e8\u003c/i\u003e(89), 5663. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.21105/joss.05663\"\u003e10.21105/joss.05663\u003c/a\u003e","url":"https://doi.org/10.21105/joss.05663"},"osco23":{"label":"osco23","enumerator":"2","html":"Osco, L. P., Wu, Q., de Lemos, E. L., Gonçalves, W. N., Ramos, A. P. M., Li, J., \u0026 Junior, J. M. (2023). \u003ci\u003eThe Segment Anything Model (SAM) for Remote Sensing Applications: From Zero to One Shot\u003c/i\u003e. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://arxiv.org/abs/2306.16623\"\u003ehttps://arxiv.org/abs/2306.16623\u003c/a\u003e","url":"https://arxiv.org/abs/2306.16623"},"mayladan23":{"label":"mayladan23","enumerator":"3","html":"Mayladan, A., Nasrallah, H., Moughnieh, H., Shukor, M., \u0026 Ghandour, A. J. (2024). \u003ci\u003eZero-Shot Refinement of Buildings’ Segmentation Models using SAM\u003c/i\u003e. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://arxiv.org/abs/2310.01845\"\u003ehttps://arxiv.org/abs/2310.01845\u003c/a\u003e","url":"https://arxiv.org/abs/2310.01845"},"kirillov23":{"label":"kirillov23","enumerator":"4","html":"Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao, T., Whitehead, S., Berg, A. C., Lo, W.-Y., Dollár, P., \u0026 Girshick, R. (2023). \u003ci\u003eSegment Anything\u003c/i\u003e. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://arxiv.org/abs/2304.02643\"\u003ehttps://arxiv.org/abs/2304.02643\u003c/a\u003e","url":"https://arxiv.org/abs/2304.02643"},"gdal":{"label":"gdal","enumerator":"5","doi":"10.5281/zenodo.5884351","html":"GDAL/OGR contributors. (2025). \u003ci\u003eGDAL/OGR Geospatial Data Abstraction software Library\u003c/i\u003e. Open Source Geospatial Foundation. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.5281/zenodo.5884351\"\u003e10.5281/zenodo.5884351\u003c/a\u003e","url":"https://doi.org/10.5281/zenodo.5884351"},"shapely":{"label":"shapely","enumerator":"6","doi":"10.5281/zenodo.5597138","html":"Gillies, S., van der Wel, C., Van den Bossche, J., Taves, M. W., Arnott, J., Ward, B. C., \u0026 others. (2025). \u003ci\u003eShapely (Version 2.1.1)\u003c/i\u003e. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.5281/zenodo.5597138\"\u003e10.5281/zenodo.5597138\u003c/a\u003e","url":"https://doi.org/10.5281/zenodo.5597138"},"geopandas":{"label":"geopandas","enumerator":"7","doi":"10.5281/zenodo.3946761","html":"Jordahl, K., den Bossche, J. V., Fleischmann, M., Wasserman, J., McBride, J., Gerard, J., Tratner, J., Perry, M., Badaracco, A. G., Farmer, C., Hjelle, G. A., Snow, A. D., Cochran, M., Gillies, S., Culbertson, L., Bartos, M., Eubank, N., maxalbert, Bilogur, A., … Leblanc, F. (2020). \u003ci\u003egeopandas/geopandas: v0.8.1\u003c/i\u003e (v0.8.1). Zenodo. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.5281/zenodo.3946761\"\u003e10.5281/zenodo.3946761\u003c/a\u003e","url":"https://doi.org/10.5281/zenodo.3946761"},"rasterio":{"label":"rasterio","enumerator":"8","html":"Gillies, S., \u0026 others. (2013–). \u003ci\u003eRasterio: geospatial raster I/O for Python programmers\u003c/i\u003e. Mapbox. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://github.com/rasterio/rasterio\"\u003ehttps://github.com/rasterio/rasterio\u003c/a\u003e","url":"https://github.com/rasterio/rasterio"},"matplotlib":{"label":"matplotlib","enumerator":"9","doi":"https://doi.org/10.1109/MCSE.2007.55","html":"Hunter, J. D. (2007). Matplotlib: A 2D graphics environment. \u003ci\u003eComputing in Science \u0026 Engineering\u003c/i\u003e, \u003ci\u003e9\u003c/i\u003e(3), 90–95. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1109/MCSE.2007.55\"\u003ehttps://doi.org/10.1109/MCSE.2007.55\u003c/a\u003e","url":"https://doi.org/10.1109/MCSE.2007.55"},"numpy":{"label":"numpy","enumerator":"10","doi":"https://doi.org/10.1038/s41586-020-2649-2","html":"Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., van Kerkwijk, M. H., Brett, M., Haldane, A., del Río, J. F., Wiebe, M., Peterson, P., … Oliphant, T. E. (2020). Array programming with NumPy. \u003ci\u003eNature\u003c/i\u003e, \u003ci\u003e585\u003c/i\u003e(7825), 357–362. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1038/s41586-020-2649-2\"\u003ehttps://doi.org/10.1038/s41586-020-2649-2\u003c/a\u003e","url":"https://doi.org/10.1038/s41586-020-2649-2"},"opencv":{"label":"opencv","enumerator":"11","html":"Bradski, G. (2000). The OpenCV Library. \u003ci\u003eDr. Dobb’s Journal of Software Tools\u003c/i\u003e."},"openpyxl":{"label":"openpyxl","enumerator":"12","html":"Gazoni, E., \u0026 Clark, C. (2024). \u003ci\u003eOpenPyXL: A Python library to read/write Excel 2010 xlsx/xlsm/xltx/xltm files\u003c/i\u003e. Python Package. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://openpyxl.readthedocs.io\"\u003ehttps://openpyxl.readthedocs.io\u003c/a\u003e","url":"https://openpyxl.readthedocs.io"},"pandas1":{"label":"pandas1","enumerator":"13","doi":"10.5281/zenodo.3509134","html":"The Pandas Development Team. (2020). \u003ci\u003epandas-dev/pandas: Pandas\u003c/i\u003e (latest). Zenodo. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.5281/zenodo.3509134\"\u003e10.5281/zenodo.3509134\u003c/a\u003e","url":"https://doi.org/10.5281/zenodo.3509134"},"pandas2":{"label":"pandas2","enumerator":"14","doi":"https://doi.org/10.25080/Majora-92bf1922-00a","html":"McKinney, W. (2010). Data Structures for Statistical Computing in Python. In Stéfan van der Walt \u0026 Jarrod Millman (Eds.), \u003ci\u003eProceedings of the 9th Python in Science Conference\u003c/i\u003e (pp. 56–61). \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.25080/Majora-92bf1922-00a\"\u003ehttps://doi.org/10.25080/Majora-92bf1922-00a\u003c/a\u003e","url":"https://doi.org/10.25080/Majora-92bf1922-00a"},"pillow":{"label":"pillow","enumerator":"15","html":"Clark, A. (2015). \u003ci\u003ePillow (PIL Fork) Documentation\u003c/i\u003e. readthedocs. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://buildmedia.readthedocs.org/media/pdf/pillow/latest/pillow.pdf\"\u003ehttps://buildmedia.readthedocs.org/media/pdf/pillow/latest/pillow.pdf\u003c/a\u003e","url":"https://buildmedia.readthedocs.org/media/pdf/pillow/latest/pillow.pdf"},"pytorch":{"label":"pytorch","enumerator":"16","html":"Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Köpf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., … Chintala, S. (2019). PyTorch: An Imperative Style, High‑Performance Deep Learning Library. \u003ci\u003eCoRR\u003c/i\u003e, \u003ci\u003eabs/1912.01703\u003c/i\u003e. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://arxiv.org/abs/1912.01703\"\u003ehttps://arxiv.org/abs/1912.01703\u003c/a\u003e","url":"https://arxiv.org/abs/1912.01703"},"qgis":{"label":"qgis","enumerator":"17","html":"QGIS Development Team. (2021). \u003ci\u003eQGIS Geographic Information System\u003c/i\u003e. QGIS Association. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://www.qgis.org\"\u003ehttps://www.qgis.org\u003c/a\u003e","url":"https://www.qgis.org"}}}},"footer":{"navigation":{}},"domain":"http://localhost:3000"}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/myst_assets_folder/manifest-998F9996.js";
import * as route0 from "/myst_assets_folder/root-TE4XH6NL.js";
import * as route1 from "/myst_assets_folder/routes/_index-GVPSY24U.js";
window.__remixRouteModules = {"root":route0,"routes/_index":route1};

import("/myst_assets_folder/entry.client-MRWD3U4M.js");</script>
<script>
  document.addEventListener('DOMContentLoaded', () => {
    // Remove the Document Outline nav
    const navElement = document.querySelector('nav[aria-label="Document Outline"]');
    if (navElement) {
      navElement.remove();
    }

    // Remove the theme toggle button
    const themeToggleButton = document.querySelector('button[aria-label="Toggle theme between light and dark mode."]');
    if (themeToggleButton) {
      themeToggleButton.remove();
    }
  });
</script>
</body></html>